{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db509470-cb51-4c21-84ca-5f928073d68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Name: /device:GPU:0\n",
      "Memory Limit: 4158652416 bytes\n",
      "Description: device: 0, name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_gpu_details():\n",
    "    devices = device_lib.list_local_devices()\n",
    "    for device in devices:\n",
    "        if device.device_type == 'GPU':\n",
    "            print(f\"Device Name: {device.name}\")\n",
    "            print(f\"Memory Limit: {device.memory_limit} bytes\")\n",
    "            print(f\"Description: {device.physical_device_desc}\")\n",
    "\n",
    "get_gpu_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da176501-fac2-4cda-b1fa-da4a5a40e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7e0a3-09ee-4768-a2a5-f95662ac28a6",
   "metadata": {},
   "source": [
    "## Loading the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a67cfeb-9428-4137-b946-d2d581b70af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>tok_0_token</th>\n",
       "      <th>tok_0_tag</th>\n",
       "      <th>tok_0_dep</th>\n",
       "      <th>...</th>\n",
       "      <th>tok_121_dep</th>\n",
       "      <th>tok_122_token</th>\n",
       "      <th>tok_122_tag</th>\n",
       "      <th>tok_122_dep</th>\n",
       "      <th>tok_123_token</th>\n",
       "      <th>tok_123_tag</th>\n",
       "      <th>tok_123_dep</th>\n",
       "      <th>tok_124_token</th>\n",
       "      <th>tok_124_tag</th>\n",
       "      <th>tok_124_dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>L1044</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>u0</td>\n",
       "      <td>L1044</td>\n",
       "      <td>None</td>\n",
       "      <td>m0</td>\n",
       "      <td>They</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>L1044</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>u2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>m0</td>\n",
       "      <td>They</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>L984</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>u0</td>\n",
       "      <td>L984</td>\n",
       "      <td>None</td>\n",
       "      <td>m0</td>\n",
       "      <td>I</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>L984</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>u2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>m0</td>\n",
       "      <td>She</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>L924</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>u0</td>\n",
       "      <td>L924</td>\n",
       "      <td>None</td>\n",
       "      <td>m0</td>\n",
       "      <td>Let</td>\n",
       "      <td>VB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 382 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id conversation_id          text speaker reply_to timestamp movie_id  \\\n",
       "0  L1045           L1044  They do not!      u0    L1044      None       m0   \n",
       "1  L1044           L1044   They do to!      u2     None      None       m0   \n",
       "2   L985            L984    I hope so.      u0     L984      None       m0   \n",
       "3   L984            L984     She okay?      u2     None      None       m0   \n",
       "4   L925            L924     Let's go.      u0     L924      None       m0   \n",
       "\n",
       "  tok_0_token tok_0_tag tok_0_dep  ... tok_121_dep tok_122_token tok_122_tag  \\\n",
       "0        They       PRP     nsubj  ...        None          None        None   \n",
       "1        They       PRP     nsubj  ...        None          None        None   \n",
       "2           I       PRP     nsubj  ...        None          None        None   \n",
       "3         She       PRP     nsubj  ...        None          None        None   \n",
       "4         Let        VB      ROOT  ...        None          None        None   \n",
       "\n",
       "  tok_122_dep tok_123_token tok_123_tag tok_123_dep tok_124_token tok_124_tag  \\\n",
       "0        None          None        None        None          None        None   \n",
       "1        None          None        None        None          None        None   \n",
       "2        None          None        None        None          None        None   \n",
       "3        None          None        None        None          None        None   \n",
       "4        None          None        None        None          None        None   \n",
       "\n",
       "  tok_124_dep  \n",
       "0        None  \n",
       "1        None  \n",
       "2        None  \n",
       "3        None  \n",
       "4        None  \n",
       "\n",
       "[5 rows x 382 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the DataFrame\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "file_path_parquet = os.path.join(data_dir, 'utterances.parquet')\n",
    "df_loaded_parquet = pd.read_parquet(file_path_parquet)\n",
    "\n",
    "df_loaded_parquet.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4870a0-f637-49e6-816f-679310801978",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5f982-c2cb-40b8-b95c-54237d3020ca",
   "metadata": {},
   "source": [
    "### Leaving only necessary data for simple Sec2Seq model\n",
    "Id, conversation_id for tracking the flow of conversations and reply_to for understanding the sequence within the dialogue, and conversation text ofcourse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "830f8a5d-17a2-47ce-bee6-bace5e54cb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>reply_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They do not!</td>\n",
       "      <td>L1045</td>\n",
       "      <td>L1044</td>\n",
       "      <td>L1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They do to!</td>\n",
       "      <td>L1044</td>\n",
       "      <td>L1044</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I hope so.</td>\n",
       "      <td>L985</td>\n",
       "      <td>L984</td>\n",
       "      <td>L984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She okay?</td>\n",
       "      <td>L984</td>\n",
       "      <td>L984</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Let's go.</td>\n",
       "      <td>L925</td>\n",
       "      <td>L924</td>\n",
       "      <td>L924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text     id conversation_id reply_to\n",
       "0  They do not!  L1045           L1044    L1044\n",
       "1   They do to!  L1044           L1044     None\n",
       "2    I hope so.   L985            L984     L984\n",
       "3     She okay?   L984            L984     None\n",
       "4     Let's go.   L925            L924     L924"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations = df_loaded_parquet[['text', 'id', 'conversation_id', 'reply_to']]\n",
    "conversations.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5150d2f-999d-45ad-b2f2-b9b65b883e89",
   "metadata": {},
   "source": [
    "## Create prepocessing functions for initial text and later response generation preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6648d492-f4e0-40a8-a3ff-012fa0a0d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa686422-2775-486c-9494-1249a4ded206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tomui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tomui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tomui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\tomui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')  # Tokenizer\n",
    "nltk.download('wordnet')  # Lemmatizer\n",
    "nltk.download('stopwords')  # Stopwords\n",
    "nltk.download('omw-1.4') # Ensures multilingual contexts\n",
    "\n",
    "# Stopwords list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "initial_preprocessing = True\n",
    "\n",
    "# Load spaCy's English NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"[^a-z0-9.,!? ]\", ' ', text)  # Keeps basic punctuation if remove punctuation is not applied\n",
    "    text = re.sub(r'\\d+', '<num>', text)\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "    return text\n",
    "\n",
    "def remove_names(text: str) -> str:\n",
    "    # Use spaCy to detect and remove names from the text\n",
    "    doc = nlp(text)\n",
    "    filtered_text = ' '.join([token.text for token in doc if token.ent_type_ != 'PERSON']) # Takes really long time, exlude from chatbot input preprocessing\n",
    "    return filtered_text\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    # Normalize text\n",
    "    text = normalize_text(text)\n",
    "    # Remove names using spaCy's NER\n",
    "    if initial_preprocessing:\n",
    "        text = remove_names(text)\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stopwords and tokenize\n",
    "    words = word_tokenize(text) # More intelligent splitting\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    # Lemmatize words\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    # Add <SOS> and <EOS> tokens, and join the list into a single string\n",
    "    return ' '.join(['sofs'] + lemmatized_words + ['eofs']) # Chosen ['sofs', 'eofs'] because tokenizer removes everthing what is in <> or || and are not in dataset vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d54043-f92c-487e-92cf-51258502844a",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f48954-ee6f-45e9-9c64-aad22ba14caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to each row in the 'text' column\n",
    "conversations['preprocessed_text'] = conversations['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f30d2-b581-4171-9ab2-e4d13edd042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations[1140: 1150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a48802-4be9-4ff0-a40e-f3875b3b2502",
   "metadata": {},
   "source": [
    "## Saving the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a0af574-6748-467b-8ba6-4da51794c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e4e2a98-f1d4-4f72-b95e-6a75f457e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0fc4148-3397-41bc-abd0-6fcee5150134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving the DataFrame\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "file_path_parquet = os.path.join(data_dir, 'preprocessed_s2s.parquet')\n",
    "conversations.to_parquet(file_path_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa83ea5-56e5-4411-8b15-aa9dd738e2bb",
   "metadata": {},
   "source": [
    "## Loading the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5d5288d3-344d-4036-b8ab-1a6641f76150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the DataFrame\n",
    "file_path_parquet = os.path.join(data_dir, 'preprocessed_s2s.parquet')\n",
    "conversations = pd.read_parquet(file_path_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "02ebe768-9135-4cd1-a662-792d7465d98e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>Why'd you help me back there with the Chief?  ...</td>\n",
       "      <td>L3229</td>\n",
       "      <td>L3229</td>\n",
       "      <td>None</td>\n",
       "      <td>sofs help back chief stand like eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>How you go out on a limb for somebody is by gi...</td>\n",
       "      <td>L3228</td>\n",
       "      <td>L3223</td>\n",
       "      <td>L3227</td>\n",
       "      <td>sofs go limb somebody giving number immigratio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>But, I mean, didn't you ever go out on a limb ...</td>\n",
       "      <td>L3227</td>\n",
       "      <td>L3223</td>\n",
       "      <td>L3226</td>\n",
       "      <td>sofs mean ever go limb somebody mean shoulda h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>Well, it's not up to you to decide whether she...</td>\n",
       "      <td>L3226</td>\n",
       "      <td>L3223</td>\n",
       "      <td>L3225</td>\n",
       "      <td>sofs well decide whether innocent understand p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>I told you, you know, I thought I was doing th...</td>\n",
       "      <td>L3225</td>\n",
       "      <td>L3223</td>\n",
       "      <td>L3224</td>\n",
       "      <td>sofs told know thought right thing know think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>No, I don't think you were a fool, I just thin...</td>\n",
       "      <td>L3224</td>\n",
       "      <td>L3223</td>\n",
       "      <td>L3223</td>\n",
       "      <td>sofs think fool think stupid mean say least ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>Yeah, just her in the shower.  Nothing happene...</td>\n",
       "      <td>L3223</td>\n",
       "      <td>L3223</td>\n",
       "      <td>None</td>\n",
       "      <td>sofs yeah shower nothing happened look sure pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>Just a shower?</td>\n",
       "      <td>L3222</td>\n",
       "      <td>L3219</td>\n",
       "      <td>L3221</td>\n",
       "      <td>sofs shower eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>I took her there for a shower and that's it.</td>\n",
       "      <td>L3221</td>\n",
       "      <td>L3219</td>\n",
       "      <td>L3220</td>\n",
       "      <td>sofs took shower eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>Well, you shoulda because nobody's gonna belie...</td>\n",
       "      <td>L3220</td>\n",
       "      <td>L3219</td>\n",
       "      <td>L3219</td>\n",
       "      <td>sofs well shoulda nobody gon na believe includ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     id  \\\n",
       "1140  Why'd you help me back there with the Chief?  ...  L3229   \n",
       "1141  How you go out on a limb for somebody is by gi...  L3228   \n",
       "1142  But, I mean, didn't you ever go out on a limb ...  L3227   \n",
       "1143  Well, it's not up to you to decide whether she...  L3226   \n",
       "1144  I told you, you know, I thought I was doing th...  L3225   \n",
       "1145  No, I don't think you were a fool, I just thin...  L3224   \n",
       "1146  Yeah, just her in the shower.  Nothing happene...  L3223   \n",
       "1147                                     Just a shower?  L3222   \n",
       "1148       I took her there for a shower and that's it.  L3221   \n",
       "1149  Well, you shoulda because nobody's gonna belie...  L3220   \n",
       "\n",
       "     conversation_id reply_to  \\\n",
       "1140           L3229     None   \n",
       "1141           L3223    L3227   \n",
       "1142           L3223    L3226   \n",
       "1143           L3223    L3225   \n",
       "1144           L3223    L3224   \n",
       "1145           L3223    L3223   \n",
       "1146           L3223     None   \n",
       "1147           L3219    L3221   \n",
       "1148           L3219    L3220   \n",
       "1149           L3219    L3219   \n",
       "\n",
       "                                      preprocessed_text  \n",
       "1140               sofs help back chief stand like eofs  \n",
       "1141  sofs go limb somebody giving number immigratio...  \n",
       "1142  sofs mean ever go limb somebody mean shoulda h...  \n",
       "1143  sofs well decide whether innocent understand p...  \n",
       "1144  sofs told know thought right thing know think ...  \n",
       "1145  sofs think fool think stupid mean say least ou...  \n",
       "1146  sofs yeah shower nothing happened look sure pr...  \n",
       "1147                                   sofs shower eofs  \n",
       "1148                              sofs took shower eofs  \n",
       "1149  sofs well shoulda nobody gon na believe includ...  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations[1140: 1150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ebdc30-1988-4230-8a02-e46978cff38e",
   "metadata": {},
   "source": [
    "## Initialize and save the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c09171e6-f737-4e3b-b2d4-67f7980a9058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved to C:\\Users\\tomui\\Desktop\\capstone_project\\data\\tokenizer.pickle\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "\n",
    "# Fit the tokenizer on the modified text data that includes <start> and <end> tokens\n",
    "tokenizer.fit_on_texts(conversations['preprocessed_text']) # <SOS> and <EOS> == sofs an eofs  == <start> and <end>\n",
    "\n",
    "# Determine the directory where the tokenizer will be saved\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Save the tokenizer using pickle\n",
    "tokenizer_path = os.path.join(data_dir, 'tokenizer.pickle')\n",
    "with open(tokenizer_path, 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Tokenizer saved to {tokenizer_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e332df38-04f5-4261-a544-786538749051",
   "metadata": {},
   "source": [
    "## Load the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3e087632-daab-4026-862e-0c7b33ebe0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the tokenizer from file\n",
    "# data_dir = os.path.join(os.getcwd(), 'data')\n",
    "# tokenizer_path = os.path.join(data_dir, 'tokenizer.pickle')\n",
    "# with open(tokenizer_path, 'rb') as handle:\n",
    "#     tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4c78c771-eb63-499b-9f47-483d825bf9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['sofs'], tokenizer.word_index['eofs']) # Checking if <start> and <end> tokens are in index (vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "eed2bb9f-a5db-4bf1-962d-810dabe5247c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sofs', 304713), ('eofs', 304713), ('know', 22895), ('like', 15314), ('get', 15014), ('got', 13322), ('u', 13080), ('want', 12128), ('think', 11251), ('one', 11186)]\n",
      "[('ese', 1), ('whatchu', 1), ('mafiya', 1), ('chechnya', 1), ('toady', 1), ('betterment', 1), ('ivans', 1), ('nihilistic', 1), ('freelancing', 1), ('gatherer', 1), ('overview', 1), ('retardant', 1), ('deploys', 1), ('beastie', 1), ('ozzfest', 1), ('russkie', 1), ('shaver', 1), ('polynesia', 1), ('mersh', 1), ('slovo', 1), ('dawning', 1), ('tshirt', 1), ('dishonorably', 1), ('vandal', 1), ('grozny', 1), ('lamborghini', 1), ('genoa', 1), ('pizda', 1), ('filament', 1), ('replicate', 1), ('solider', 1), ('secaucus', 1), ('athletics', 1), ('herded', 1), ('wolverine', 1), ('absorbs', 1), ('definitively', 1), ('poppycock', 1), ('rumous', 1), ('celery', 1), ('cerebrum', 1), ('unashamedly', 1), ('dien', 1), ('gerhart', 1), ('mending', 1), ('galvanism', 1), ('equalize', 1), ('cerebrospinal', 1), ('madein', 1), ('froderick', 1), ('blindingly', 1), ('ascend', 1), ('diagnostician', 1), ('sockers', 1), ('fockers', 1), ('fredereck', 1), ('frodereck', 1), ('fronkon', 1), ('ereck', 1), ('dereck', 1), ('mmmmmmmmmm', 1), ('mmmmmmmmmmmmmmmmmmmmmmmmm', 1), ('pah', 1), ('mmmmmmmmmmm', 1), ('mmmmmmmmmmmmmnnnnnnmmmmmmmm', 1), ('transylvanian', 1), ('apfelstrudel', 1), ('mmmmmmmmmmmmmmm', 1), ('fuchsmachen', 1), ('liebe', 1), ('danc', 1), ('ul', 1), ('tra', 1), ('sacral', 1), ('minuteness', 1), ('schwanzstucker', 1), ('grrrhmmnnnjkjmmmnn', 1), ('roughhousing', 1), ('foooooood', 1), ('dooty', 1), ('lifebuoy', 1), ('saij', 1), ('peifecl', 1), ('meseif', 1), ('wellington', 1), ('lorj', 1), ('cetshwayo', 1), ('manoeuvre', 1), ('indeedldid', 1), ('mylord', 1), ('itwas', 1), ('ofthe', 1), ('adc', 1), ('ofnatal', 1), ('subaltern', 1), ('horsemanship', 1), ('splendil', 1), ('bombardier', 1), ('impi', 1), ('basuto', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Top words in dictionary\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Sort the word_counts dictionary by frequency in descending order\n",
    "sorted_word_counts = OrderedDict(sorted(tokenizer.word_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Display the sorted word counts\n",
    "print(list(sorted_word_counts.items())[:10])\n",
    "print(list(sorted_word_counts.items())[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d0558-1fec-450f-b5d7-7f4bb4bfb150",
   "metadata": {},
   "source": [
    "## Pairing messages - input with responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "92f8d5e7-8194-4470-935d-f73dfeb25de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the DataFrame with itself to form pairs\n",
    "pairs = pd.merge(\n",
    "    conversations, conversations,\n",
    "    left_on='id',\n",
    "    right_on='reply_to',\n",
    "    suffixes=('_input', '_response')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "35930c1b-f970-48cb-8eb1-b11457a0de85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_input</th>\n",
       "      <th>id_input</th>\n",
       "      <th>conversation_id_input</th>\n",
       "      <th>reply_to_input</th>\n",
       "      <th>preprocessed_text_input</th>\n",
       "      <th>text_response</th>\n",
       "      <th>id_response</th>\n",
       "      <th>conversation_id_response</th>\n",
       "      <th>reply_to_response</th>\n",
       "      <th>preprocessed_text_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They do to!</td>\n",
       "      <td>L1044</td>\n",
       "      <td>L1044</td>\n",
       "      <td>None</td>\n",
       "      <td>sofs eofs</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>L1045</td>\n",
       "      <td>L1044</td>\n",
       "      <td>L1044</td>\n",
       "      <td>sofs eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She okay?</td>\n",
       "      <td>L984</td>\n",
       "      <td>L984</td>\n",
       "      <td>None</td>\n",
       "      <td>sofs okay eofs</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>L985</td>\n",
       "      <td>L984</td>\n",
       "      <td>L984</td>\n",
       "      <td>sofs hope eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow</td>\n",
       "      <td>L924</td>\n",
       "      <td>L924</td>\n",
       "      <td>None</td>\n",
       "      <td>sofs wow eofs</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>L925</td>\n",
       "      <td>L924</td>\n",
       "      <td>L924</td>\n",
       "      <td>sofs let go eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>L871</td>\n",
       "      <td>L870</td>\n",
       "      <td>L870</td>\n",
       "      <td>sofs eofs</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "      <td>L872</td>\n",
       "      <td>L870</td>\n",
       "      <td>L871</td>\n",
       "      <td>sofs okay gon na need learn lie eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>L870</td>\n",
       "      <td>L870</td>\n",
       "      <td>None</td>\n",
       "      <td>sofs kidding know sometimes become persona kno...</td>\n",
       "      <td>No</td>\n",
       "      <td>L871</td>\n",
       "      <td>L870</td>\n",
       "      <td>L870</td>\n",
       "      <td>sofs eofs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_input id_input  \\\n",
       "0                                        They do to!    L1044   \n",
       "1                                          She okay?     L984   \n",
       "2                                                Wow     L924   \n",
       "3                                                 No     L871   \n",
       "4  I'm kidding.  You know how sometimes you just ...     L870   \n",
       "\n",
       "  conversation_id_input reply_to_input  \\\n",
       "0                 L1044           None   \n",
       "1                  L984           None   \n",
       "2                  L924           None   \n",
       "3                  L870           L870   \n",
       "4                  L870           None   \n",
       "\n",
       "                             preprocessed_text_input  \\\n",
       "0                                          sofs eofs   \n",
       "1                                     sofs okay eofs   \n",
       "2                                      sofs wow eofs   \n",
       "3                                          sofs eofs   \n",
       "4  sofs kidding know sometimes become persona kno...   \n",
       "\n",
       "                                    text_response id_response  \\\n",
       "0                                    They do not!       L1045   \n",
       "1                                      I hope so.        L985   \n",
       "2                                       Let's go.        L925   \n",
       "3  Okay -- you're gonna need to learn how to lie.        L872   \n",
       "4                                              No        L871   \n",
       "\n",
       "  conversation_id_response reply_to_response  \\\n",
       "0                    L1044             L1044   \n",
       "1                     L984              L984   \n",
       "2                     L924              L924   \n",
       "3                     L870              L871   \n",
       "4                     L870              L870   \n",
       "\n",
       "             preprocessed_text_response  \n",
       "0                             sofs eofs  \n",
       "1                        sofs hope eofs  \n",
       "2                      sofs let go eofs  \n",
       "3  sofs okay gon na need learn lie eofs  \n",
       "4                             sofs eofs  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "52d11b65-699e-466f-bfe3-8bdb6dd9ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the needed columns including IDs\n",
    "training_data = pairs[['id_input', 'text_input', 'preprocessed_text_input', 'id_response', 'text_response', 'preprocessed_text_response']]\n",
    "\n",
    "# Renaming columns for clarity\n",
    "training_data.columns = ['ID_Input', 'Original_Text_Input', 'Text_Input', 'ID_Response', 'Original_Text_Response', 'Text_Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "77360369-d243-4092-be7b-f766ddcd249b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Input</th>\n",
       "      <th>Original_Text_Input</th>\n",
       "      <th>Text_Input</th>\n",
       "      <th>ID_Response</th>\n",
       "      <th>Original_Text_Response</th>\n",
       "      <th>Text_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1044</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>sofs eofs</td>\n",
       "      <td>L1045</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>sofs eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L984</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>sofs okay eofs</td>\n",
       "      <td>L985</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>sofs hope eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L924</td>\n",
       "      <td>Wow</td>\n",
       "      <td>sofs wow eofs</td>\n",
       "      <td>L925</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>sofs let go eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L871</td>\n",
       "      <td>No</td>\n",
       "      <td>sofs eofs</td>\n",
       "      <td>L872</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "      <td>sofs okay gon na need learn lie eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L870</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>sofs kidding know sometimes become persona kno...</td>\n",
       "      <td>L871</td>\n",
       "      <td>No</td>\n",
       "      <td>sofs eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221611</th>\n",
       "      <td>L666520</td>\n",
       "      <td>Well I assure you, Sir, I have no desire to cr...</td>\n",
       "      <td>sofs well assure sir desire create difficulty ...</td>\n",
       "      <td>L666521</td>\n",
       "      <td>And I assure you, you do not In fact I'd be ob...</td>\n",
       "      <td>sofs assure fact obliged best advice scout see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221612</th>\n",
       "      <td>L666371</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "      <td>sofs lord chelmsford seems want stay back basu...</td>\n",
       "      <td>L666372</td>\n",
       "      <td>I think Chelmsford wants a good man on the bor...</td>\n",
       "      <td>sofs think chelmsford want good man border fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221613</th>\n",
       "      <td>L666370</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>sofs take sikali main column river eofs</td>\n",
       "      <td>L666371</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "      <td>sofs lord chelmsford seems want stay back basu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221614</th>\n",
       "      <td>L666369</td>\n",
       "      <td>Your orders, Mr Vereker?</td>\n",
       "      <td>sofs order mr vereker eofs</td>\n",
       "      <td>L666370</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>sofs take sikali main column river eofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221615</th>\n",
       "      <td>L666256</td>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "      <td>sofs colonel durnford hear seeking officer eofs</td>\n",
       "      <td>L666257</td>\n",
       "      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n",
       "      <td>sofs good one yes mr vereker gentleman ride sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221616 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID_Input                                Original_Text_Input  \\\n",
       "0         L1044                                        They do to!   \n",
       "1          L984                                          She okay?   \n",
       "2          L924                                                Wow   \n",
       "3          L871                                                 No   \n",
       "4          L870  I'm kidding.  You know how sometimes you just ...   \n",
       "...         ...                                                ...   \n",
       "221611  L666520  Well I assure you, Sir, I have no desire to cr...   \n",
       "221612  L666371  Lord Chelmsford seems to want me to stay back ...   \n",
       "221613  L666370  I'm to take the Sikali with the main column to...   \n",
       "221614  L666369                           Your orders, Mr Vereker?   \n",
       "221615  L666256  Colonel Durnford... William Vereker. I hear yo...   \n",
       "\n",
       "                                               Text_Input ID_Response  \\\n",
       "0                                               sofs eofs       L1045   \n",
       "1                                          sofs okay eofs        L985   \n",
       "2                                           sofs wow eofs        L925   \n",
       "3                                               sofs eofs        L872   \n",
       "4       sofs kidding know sometimes become persona kno...        L871   \n",
       "...                                                   ...         ...   \n",
       "221611  sofs well assure sir desire create difficulty ...     L666521   \n",
       "221612  sofs lord chelmsford seems want stay back basu...     L666372   \n",
       "221613            sofs take sikali main column river eofs     L666371   \n",
       "221614                         sofs order mr vereker eofs     L666370   \n",
       "221615    sofs colonel durnford hear seeking officer eofs     L666257   \n",
       "\n",
       "                                   Original_Text_Response  \\\n",
       "0                                            They do not!   \n",
       "1                                              I hope so.   \n",
       "2                                               Let's go.   \n",
       "3          Okay -- you're gonna need to learn how to lie.   \n",
       "4                                                      No   \n",
       "...                                                   ...   \n",
       "221611  And I assure you, you do not In fact I'd be ob...   \n",
       "221612  I think Chelmsford wants a good man on the bor...   \n",
       "221613  Lord Chelmsford seems to want me to stay back ...   \n",
       "221614  I'm to take the Sikali with the main column to...   \n",
       "221615  Good ones, yes, Mr Vereker. Gentlemen who can ...   \n",
       "\n",
       "                                            Text_Response  \n",
       "0                                               sofs eofs  \n",
       "1                                          sofs hope eofs  \n",
       "2                                        sofs let go eofs  \n",
       "3                    sofs okay gon na need learn lie eofs  \n",
       "4                                               sofs eofs  \n",
       "...                                                   ...  \n",
       "221611  sofs assure fact obliged best advice scout see...  \n",
       "221612  sofs think chelmsford want good man border fea...  \n",
       "221613  sofs lord chelmsford seems want stay back basu...  \n",
       "221614            sofs take sikali main column river eofs  \n",
       "221615  sofs good one yes mr vereker gentleman ride sh...  \n",
       "\n",
       "[221616 rows x 6 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5788cd03-4935-46a7-ba5b-d5b1db589dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221616 entries, 0 to 221615\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   ID_Input                221616 non-null  object\n",
      " 1   Original_Text_Input     221616 non-null  object\n",
      " 2   Text_Input              221616 non-null  object\n",
      " 3   ID_Response             221616 non-null  object\n",
      " 4   Original_Text_Response  221616 non-null  object\n",
      " 5   Text_Response           221616 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "training_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b27b835-1776-4f74-8ad3-f95ef61a2bb5",
   "metadata": {},
   "source": [
    "## Variables for configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9e7db9ee-0add-4ad6-8956-553e60ba5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10 # Variable for padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da43088-9b1a-43f4-968c-ae195c5b65fe",
   "metadata": {},
   "source": [
    "## Converting to indices and input-output sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "43711765-e472-4819-b990-cc48f5499a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomui\\AppData\\Local\\Temp\\ipykernel_133292\\1814316150.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_data['Padded_Input_Sequences'] = list(map(np.array, input_padded))\n",
      "C:\\Users\\tomui\\AppData\\Local\\Temp\\ipykernel_133292\\1814316150.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_data['Padded_Target_Sequences'] = list(map(np.array, target_padded))\n"
     ]
    }
   ],
   "source": [
    "# Convert texts to sequences\n",
    "input_sequences = tokenizer.texts_to_sequences(training_data['Text_Input'])\n",
    "target_sequences = tokenizer.texts_to_sequences(training_data['Text_Response'])\n",
    "\n",
    "# Pad sequences\n",
    "input_padded = pad_sequences(input_sequences, maxlen=max_length, padding='post')\n",
    "target_padded = pad_sequences(target_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Store numpy arrays directly in the DataFrame\n",
    "training_data['Padded_Input_Sequences'] = list(map(np.array, input_padded))\n",
    "training_data['Padded_Target_Sequences'] = list(map(np.array, target_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "90513ebe-543c-44c8-9eb5-21d9a7bdc9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Input</th>\n",
       "      <th>Original_Text_Input</th>\n",
       "      <th>Text_Input</th>\n",
       "      <th>ID_Response</th>\n",
       "      <th>Original_Text_Response</th>\n",
       "      <th>Text_Response</th>\n",
       "      <th>Padded_Input_Sequences</th>\n",
       "      <th>Padded_Target_Sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1044</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>sofs eofs</td>\n",
       "      <td>L1045</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>sofs eofs</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L984</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>sofs okay eofs</td>\n",
       "      <td>L985</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>sofs hope eofs</td>\n",
       "      <td>[1, 38, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 235, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L924</td>\n",
       "      <td>Wow</td>\n",
       "      <td>sofs wow eofs</td>\n",
       "      <td>L925</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>sofs let go eofs</td>\n",
       "      <td>[1, 791, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 28, 11, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L871</td>\n",
       "      <td>No</td>\n",
       "      <td>sofs eofs</td>\n",
       "      <td>L872</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "      <td>sofs okay gon na need learn lie eofs</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 38, 45, 36, 42, 514, 421, 2, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L870</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>sofs kidding know sometimes become persona kno...</td>\n",
       "      <td>L871</td>\n",
       "      <td>No</td>\n",
       "      <td>sofs eofs</td>\n",
       "      <td>[1, 541, 3, 349, 590, 3, 663, 2, 0, 0]</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221611</th>\n",
       "      <td>L666520</td>\n",
       "      <td>Well I assure you, Sir, I have no desire to cr...</td>\n",
       "      <td>sofs well assure sir desire create difficulty ...</td>\n",
       "      <td>L666521</td>\n",
       "      <td>And I assure you, you do not In fact I'd be ob...</td>\n",
       "      <td>sofs assure fact obliged best advice scout see...</td>\n",
       "      <td>[1, 13, 2210, 68, 1655, 1801, 4099, 44, 2, 0]</td>\n",
       "      <td>[1, 2210, 358, 5036, 174, 1053, 2707, 171, 2, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221612</th>\n",
       "      <td>L666371</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "      <td>sofs lord chelmsford seems want stay back basu...</td>\n",
       "      <td>L666372</td>\n",
       "      <td>I think Chelmsford wants a good man on the bor...</td>\n",
       "      <td>sofs think chelmsford want good man border fea...</td>\n",
       "      <td>[1, 602, 416, 8, 146, 27, 2, 0, 0, 0]</td>\n",
       "      <td>[19, 31, 2047, 725, 741, 3415, 2135, 1207, 422...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221613</th>\n",
       "      <td>L666370</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>sofs take sikali main column river eofs</td>\n",
       "      <td>L666371</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "      <td>sofs lord chelmsford seems want stay back basu...</td>\n",
       "      <td>[1, 29, 1285, 2892, 971, 2, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 602, 416, 8, 146, 27, 2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221614</th>\n",
       "      <td>L666369</td>\n",
       "      <td>Your orders, Mr Vereker?</td>\n",
       "      <td>sofs order mr vereker eofs</td>\n",
       "      <td>L666370</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>sofs take sikali main column river eofs</td>\n",
       "      <td>[1, 383, 39, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 29, 1285, 2892, 971, 2, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221615</th>\n",
       "      <td>L666256</td>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "      <td>sofs colonel durnford hear seeking officer eofs</td>\n",
       "      <td>L666257</td>\n",
       "      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n",
       "      <td>sofs good one yes mr vereker gentleman ride sh...</td>\n",
       "      <td>[1, 1016, 132, 5213, 576, 2, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 19, 10, 20, 39, 598, 503, 406, 2, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221616 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID_Input                                Original_Text_Input  \\\n",
       "0         L1044                                        They do to!   \n",
       "1          L984                                          She okay?   \n",
       "2          L924                                                Wow   \n",
       "3          L871                                                 No   \n",
       "4          L870  I'm kidding.  You know how sometimes you just ...   \n",
       "...         ...                                                ...   \n",
       "221611  L666520  Well I assure you, Sir, I have no desire to cr...   \n",
       "221612  L666371  Lord Chelmsford seems to want me to stay back ...   \n",
       "221613  L666370  I'm to take the Sikali with the main column to...   \n",
       "221614  L666369                           Your orders, Mr Vereker?   \n",
       "221615  L666256  Colonel Durnford... William Vereker. I hear yo...   \n",
       "\n",
       "                                               Text_Input ID_Response  \\\n",
       "0                                               sofs eofs       L1045   \n",
       "1                                          sofs okay eofs        L985   \n",
       "2                                           sofs wow eofs        L925   \n",
       "3                                               sofs eofs        L872   \n",
       "4       sofs kidding know sometimes become persona kno...        L871   \n",
       "...                                                   ...         ...   \n",
       "221611  sofs well assure sir desire create difficulty ...     L666521   \n",
       "221612  sofs lord chelmsford seems want stay back basu...     L666372   \n",
       "221613            sofs take sikali main column river eofs     L666371   \n",
       "221614                         sofs order mr vereker eofs     L666370   \n",
       "221615    sofs colonel durnford hear seeking officer eofs     L666257   \n",
       "\n",
       "                                   Original_Text_Response  \\\n",
       "0                                            They do not!   \n",
       "1                                              I hope so.   \n",
       "2                                               Let's go.   \n",
       "3          Okay -- you're gonna need to learn how to lie.   \n",
       "4                                                      No   \n",
       "...                                                   ...   \n",
       "221611  And I assure you, you do not In fact I'd be ob...   \n",
       "221612  I think Chelmsford wants a good man on the bor...   \n",
       "221613  Lord Chelmsford seems to want me to stay back ...   \n",
       "221614  I'm to take the Sikali with the main column to...   \n",
       "221615  Good ones, yes, Mr Vereker. Gentlemen who can ...   \n",
       "\n",
       "                                            Text_Response  \\\n",
       "0                                               sofs eofs   \n",
       "1                                          sofs hope eofs   \n",
       "2                                        sofs let go eofs   \n",
       "3                    sofs okay gon na need learn lie eofs   \n",
       "4                                               sofs eofs   \n",
       "...                                                   ...   \n",
       "221611  sofs assure fact obliged best advice scout see...   \n",
       "221612  sofs think chelmsford want good man border fea...   \n",
       "221613  sofs lord chelmsford seems want stay back basu...   \n",
       "221614            sofs take sikali main column river eofs   \n",
       "221615  sofs good one yes mr vereker gentleman ride sh...   \n",
       "\n",
       "                               Padded_Input_Sequences  \\\n",
       "0                      [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1                     [1, 38, 2, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2                    [1, 791, 2, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3                      [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4              [1, 541, 3, 349, 590, 3, 663, 2, 0, 0]   \n",
       "...                                               ...   \n",
       "221611  [1, 13, 2210, 68, 1655, 1801, 4099, 44, 2, 0]   \n",
       "221612          [1, 602, 416, 8, 146, 27, 2, 0, 0, 0]   \n",
       "221613        [1, 29, 1285, 2892, 971, 2, 0, 0, 0, 0]   \n",
       "221614              [1, 383, 39, 2, 0, 0, 0, 0, 0, 0]   \n",
       "221615       [1, 1016, 132, 5213, 576, 2, 0, 0, 0, 0]   \n",
       "\n",
       "                                  Padded_Target_Sequences  \n",
       "0                          [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1                        [1, 235, 2, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2                        [1, 28, 11, 2, 0, 0, 0, 0, 0, 0]  \n",
       "3                  [1, 38, 45, 36, 42, 514, 421, 2, 0, 0]  \n",
       "4                          [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                                   ...  \n",
       "221611   [1, 2210, 358, 5036, 174, 1053, 2707, 171, 2, 0]  \n",
       "221612  [19, 31, 2047, 725, 741, 3415, 2135, 1207, 422...  \n",
       "221613              [1, 602, 416, 8, 146, 27, 2, 0, 0, 0]  \n",
       "221614            [1, 29, 1285, 2892, 971, 2, 0, 0, 0, 0]  \n",
       "221615           [1, 19, 10, 20, 39, 598, 503, 406, 2, 0]  \n",
       "\n",
       "[221616 rows x 8 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06082790-3c51-47d0-9e2e-c4cd22cc6ebe",
   "metadata": {},
   "source": [
    "## Checking if conversion was successfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1da54ad0-2522-45a8-9b20-50106969b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: But doesn't the Son of Sam Law prevent criminals from profiting from their crimes? \n",
      "Reconstructed Text: sofs son law prevent criminal crime eofs\n",
      "Original Text: That doesn't apply to me because I'm not a criminal.  I'm not a criminal!  I wasn't convicted. \n",
      "Reconstructed Text: sofs apply criminal criminal convicted eofs\n",
      "Original Text: We're in negotiations, that's correct. \n",
      "Reconstructed Text: sofs negotiation correct eofs\n",
      "Original Text: But doesn't the Son of Sam Law prevent criminals from profiting from their crimes? \n",
      "Reconstructed Text: sofs son law prevent criminal crime eofs\n",
      "Original Text: And isn't there a movie in the works about you? \n",
      "Reconstructed Text: sofs movie work eofs\n",
      "Original Text: We're in negotiations, that's correct. \n",
      "Reconstructed Text: sofs negotiation correct eofs\n",
      "Original Text: Look, I'm in here.  You call this a career move? \n",
      "Reconstructed Text: sofs look call career move eofs\n",
      "Original Text: And isn't there a movie in the works about you? \n",
      "Reconstructed Text: sofs movie work eofs\n",
      "Original Text: Permanently disrupted?  Aren't you selling paintings now for quite a lot of money?  Hasn't this 'incident' as you call it, jump started your career as an artist? \n",
      "Reconstructed Text: quite lot money incident call jump started career artist eofs\n",
      "Original Text: Look, I'm in here.  You call this a career move? \n",
      "Reconstructed Text: sofs look call career move eofs\n",
      "Original Text: Look, I'm a victim here, too.  I was a year away from getting my masters in Art, now I'll never graduate.  My life has been permanently disrupted. \n",
      "Reconstructed Text: year away getting master art never graduate life permanently eofs\n",
      "Original Text: Permanently disrupted?  Aren't you selling paintings now for quite a lot of money?  Hasn't this 'incident' as you call it, jump started your career as an artist? \n",
      "Reconstructed Text: quite lot money incident call jump started career artist eofs\n",
      "Original Text: You seem very savvy for a man who's been found mentally incompetent to stand trial. \n",
      "Reconstructed Text: sofs seem man found mentally incompetent stand trial eofs\n",
      "Original Text: Look, I'm a victim here, too.  I was a year away from getting my masters in Art, now I'll never graduate.  My life has been permanently disrupted. \n",
      "Reconstructed Text: year away getting master art never graduate life permanently eofs\n",
      "Original Text: It was my finger that pulled the trigger, but I'm not morally responsible.  My psychiatrist knew what I was capable of.  How could I know. I'm not a doctor. \n",
      "Reconstructed Text: trigger morally responsible psychiatrist knew capable could know doctor eofs\n",
      "Original Text: You seem very savvy for a man who's been found mentally incompetent to stand trial. \n",
      "Reconstructed Text: sofs seem man found mentally incompetent stand trial eofs\n",
      "Original Text: ...so you feel absolutely no responsibility for killing these people? \n",
      "Reconstructed Text: sofs feel absolutely responsibility killing people eofs\n",
      "Original Text: It was my finger that pulled the trigger, but I'm not morally responsible.  My psychiatrist knew what I was capable of.  How could I know. I'm not a doctor. \n",
      "Reconstructed Text: trigger morally responsible psychiatrist knew capable could know doctor eofs\n",
      "Original Text: Yes.  My psychiatrist didn't insist that I stay on my medication. \n",
      "Reconstructed Text: sofs yes psychiatrist insist stay medication eofs\n",
      "Original Text: ...so you feel absolutely no responsibility for killing these people? \n",
      "Reconstructed Text: sofs feel absolutely responsibility killing people eofs\n"
     ]
    }
   ],
   "source": [
    "# Print original and reverse-tokenized text for entries\n",
    "for index, row in training_data[1130:1140].iterrows():\n",
    "    print(\"Original Text:\", row['Original_Text_Input'], \n",
    "          \"\\nReconstructed Text:\", sequences_to_text(row['Padded_Input_Sequences']))\n",
    "    print(\"Original Text:\", row['Original_Text_Response'], \n",
    "          \"\\nReconstructed Text:\", sequences_to_text(row['Padded_Target_Sequences']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a0fd035f-e78c-4aa8-9322-f5bd25f6b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the needed columns including IDs\n",
    "training_data_final = training_data[['ID_Input', 'Padded_Input_Sequences', 'ID_Response', 'Padded_Target_Sequences']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a3073d-c4d0-4791-bc90-99f3ff74ef00",
   "metadata": {},
   "source": [
    "## Saving the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0e6e6f6b-5b0a-4ad3-a3a3-22c25180fe74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving the DataFrame\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "file_path_parquet = os.path.join(data_dir, 'training_df_s2s.parquet')\n",
    "training_data_final.to_parquet(file_path_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec98bfa-c44a-42b5-8e62-c0dddebc67b9",
   "metadata": {},
   "source": [
    "## Loading the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "e3699bc1-d5ec-41d6-ba0f-de02b3905615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Input</th>\n",
       "      <th>Padded_Input_Sequences</th>\n",
       "      <th>ID_Response</th>\n",
       "      <th>Padded_Target_Sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1044</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L1045</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L984</td>\n",
       "      <td>[1, 38, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L985</td>\n",
       "      <td>[1, 235, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L924</td>\n",
       "      <td>[1, 791, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L925</td>\n",
       "      <td>[1, 28, 11, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L871</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L872</td>\n",
       "      <td>[1, 38, 45, 36, 42, 514, 421, 2, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L870</td>\n",
       "      <td>[1, 541, 3, 349, 590, 3, 663, 2, 0, 0]</td>\n",
       "      <td>L871</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L868</td>\n",
       "      <td>[1, 131, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L869</td>\n",
       "      <td>[1, 4, 725, 813, 2, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L867</td>\n",
       "      <td>[1, 19, 205, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L868</td>\n",
       "      <td>[1, 131, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L866</td>\n",
       "      <td>[1, 664, 5, 19, 205, 1913, 2, 0, 0, 0]</td>\n",
       "      <td>L867</td>\n",
       "      <td>[1, 19, 205, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L864</td>\n",
       "      <td>[1, 6220, 2142, 4, 1551, 2, 0, 0, 0, 0]</td>\n",
       "      <td>L865</td>\n",
       "      <td>[1, 117, 97, 132, 10, 213, 2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L863</td>\n",
       "      <td>[1, 913, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L864</td>\n",
       "      <td>[1, 6220, 2142, 4, 1551, 2, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_Input                   Padded_Input_Sequences ID_Response  \\\n",
       "0    L1044           [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]       L1045   \n",
       "1     L984          [1, 38, 2, 0, 0, 0, 0, 0, 0, 0]        L985   \n",
       "2     L924         [1, 791, 2, 0, 0, 0, 0, 0, 0, 0]        L925   \n",
       "3     L871           [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]        L872   \n",
       "4     L870   [1, 541, 3, 349, 590, 3, 663, 2, 0, 0]        L871   \n",
       "5     L868         [1, 131, 2, 0, 0, 0, 0, 0, 0, 0]        L869   \n",
       "6     L867        [1, 19, 205, 2, 0, 0, 0, 0, 0, 0]        L868   \n",
       "7     L866   [1, 664, 5, 19, 205, 1913, 2, 0, 0, 0]        L867   \n",
       "8     L864  [1, 6220, 2142, 4, 1551, 2, 0, 0, 0, 0]        L865   \n",
       "9     L863         [1, 913, 2, 0, 0, 0, 0, 0, 0, 0]        L864   \n",
       "\n",
       "                   Padded_Target_Sequences  \n",
       "0           [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1         [1, 235, 2, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2         [1, 28, 11, 2, 0, 0, 0, 0, 0, 0]  \n",
       "3   [1, 38, 45, 36, 42, 514, 421, 2, 0, 0]  \n",
       "4           [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "5       [1, 4, 725, 813, 2, 0, 0, 0, 0, 0]  \n",
       "6         [1, 131, 2, 0, 0, 0, 0, 0, 0, 0]  \n",
       "7        [1, 19, 205, 2, 0, 0, 0, 0, 0, 0]  \n",
       "8   [1, 117, 97, 132, 10, 213, 2, 0, 0, 0]  \n",
       "9  [1, 6220, 2142, 4, 1551, 2, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the DataFrame\n",
    "file_path_parquet = os.path.join(data_dir, 'training_df_s2s.parquet')\n",
    "training_data_final = pd.read_parquet(file_path_parquet)\n",
    "\n",
    "training_data_final.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1ca701-3079-4276-a1b2-8fdbacf72d90",
   "metadata": {},
   "source": [
    "## Checking if GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "7ac58279-25ab-4b1f-8ab3-45ccbcc54428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Name: /device:GPU:0\n",
      "Memory Limit: 4158652416 bytes\n",
      "Description: device: 0, name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_gpu_details():\n",
    "    devices = device_lib.list_local_devices()\n",
    "    for device in devices:\n",
    "        if device.device_type == 'GPU':\n",
    "            print(f\"Device Name: {device.name}\")\n",
    "            print(f\"Memory Limit: {device.memory_limit} bytes\")\n",
    "            print(f\"Description: {device.physical_device_desc}\")\n",
    "\n",
    "get_gpu_details()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f5e549-9e15-443d-b2ab-9e7b580b1263",
   "metadata": {},
   "source": [
    "## Encoder-decoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "b828bc0c-6cb0-4da9-967d-001714369e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc05218-c2ff-4634-9699-16402c5a499e",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "2de8ac49-8ff9-4c92-842a-fac638f3555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = np.array(training_data_final['Padded_Input_Sequences'].tolist())\n",
    "target_sequences = np.array(training_data_final['Padded_Target_Sequences'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "550c4e97-6363-454e-b0ef-153fec9ebf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[   1  141 1798 6223   34  314  139  127    2    0]\n",
      "[   1  309 5414 8245    6  321 2001   11    2    0]\n"
     ]
    }
   ],
   "source": [
    "print(type(input_sequences))\n",
    "print(type(target_sequences))\n",
    "print(input_sequences[88])\n",
    "print(target_sequences[88])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "4e229b7f-f9ae-4b99-987b-ca9fa67bfe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation sets\n",
    "input_train, input_val, target_train, target_val = train_test_split(input_sequences, target_sequences, test_size=0.1, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80299dbb-ec36-4ea6-b0a6-8d16b7b0442b",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ce1cf1-323b-4e80-9e25-39b0a2e13294",
   "metadata": {},
   "source": [
    "## Variables for configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "575f2db6-a37f-46c4-aadc-21b044c342ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "4bf49762-c404-4ffd-a861-538ef5d25e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_55 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_56 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_46 (Embedding)       (None, None, 50)     2050800     ['input_55[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_47 (Embedding)       (None, None, 50)     2050800     ['input_56[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_46 (LSTM)                 [(None, 256),        314368      ['embedding_46[0][0]']           \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_47 (LSTM)                 [(None, None, 256),  314368      ['embedding_47[0][0]',           \n",
      "                                 (None, 256),                     'lstm_46[0][1]',                \n",
      "                                 (None, 256)]                     'lstm_46[0][2]']                \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, None, 41016)  10541112    ['lstm_47[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,271,448\n",
      "Trainable params: 15,271,448\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(vocab_size, 50, mask_zero=True)(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = LSTM(256, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(vocab_size, 50, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + encoder_states, [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Main Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bfe3f4-af26-4b73-ab45-2cd9d5143362",
   "metadata": {},
   "source": [
    "## Variables for configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "9b00db98-9c7c-4f6b-876a-2e900c04da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e129a71-f581-4c89-8c43-0a9fe9911b06",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "ac6ec2e2-3832-42ac-bd1f-7faf53dd5073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3117/3117 [==============================] - 516s 163ms/step - loss: 2.8135 - accuracy: 0.3410 - val_loss: 2.7196 - val_accuracy: 0.3469\n",
      "Epoch 2/2\n",
      "3117/3117 [==============================] - 1402s 450ms/step - loss: 2.6709 - accuracy: 0.3488 - val_loss: 2.7057 - val_accuracy: 0.3484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x285a8cbc6a0>"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Prepare decoder input data that just contains the start token\n",
    "decoder_input_train = np.hstack([np.zeros((target_train.shape[0], 1)), target_train[:, :-1]])  # shift target sequences\n",
    "decoder_input_val = np.hstack([np.zeros((target_val.shape[0], 1)), target_val[:, :-1]])\n",
    "\n",
    "# Ensure targets are expanded in dimension to match the output shape expected by sparse_categorical_crossentropy\n",
    "target_train_exp = np.expand_dims(target_train, -1)\n",
    "target_val_exp = np.expand_dims(target_val, -1)\n",
    "\n",
    "# Fit the model using the original integer labels\n",
    "model.fit(\n",
    "    [input_train, decoder_input_train], target_train_exp,\n",
    "    validation_data=([input_val, decoder_input_val], target_val_exp),\n",
    "    epochs=epochs, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "0aff02c8-ac8b-4e63-b385-69f50e9ef665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare decoder input data that just contains the start token\n",
    "# decoder_input_train = np.hstack([np.zeros((target_train.shape[0], 1)), target_train[:, :-1]])  # shift target sequences\n",
    "# decoder_input_val = np.hstack([np.zeros((target_val.shape[0], 1)), target_val[:, :-1]])\n",
    "\n",
    "# # Fit model\n",
    "# # model.fit([input_train, decoder_input_train], np.expand_dims(target_train, -1),\n",
    "# #           validation_data=([input_val, decoder_input_val], np.expand_dims(target_val, -1)),\n",
    "# #           epochs=epochs, batch_size=batch_size)\n",
    "# model.fit(\n",
    "#     [input_train, decoder_input_train], decoder_target_data,\n",
    "#     validation_data=([input_val, decoder_input_val], to_categorical(target_val, num_classes=vocab_size)),\n",
    "#     epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef4dca2-80ae-4779-8c53-658e5e426980",
   "metadata": {},
   "source": [
    "## Generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "8463baba-3764-464e-8442-4af331332e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_preprocessing = False # Excepts spaCy to detect and remove names from the text\n",
    "\n",
    "def generate_response(input_text: str) -> str:\n",
    "    processed_text = preprocess_text(input_text)\n",
    "    input_seq = tokenizer.texts_to_sequences([processed_text])\n",
    "    input_seq = pad_sequences(input_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "    print(f\"Processed Text: {processed_text}\")\n",
    "    print(f\"Input Sequence: {input_seq}\")\n",
    "\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tokenizer.word_index['sofs']  # Start token index\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    tokens_generated = 0\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tokenizer.index_word.get(sampled_token_index, '')\n",
    "\n",
    "        print(f\"Sampled Token Index: {sampled_token_index}\")\n",
    "        print(f\"Sampled Char: {sampled_char}\")\n",
    "\n",
    "        if sampled_token_index == tokenizer.word_index['eofs'] or tokens_generated > 10:  # Stop condition\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_char\n",
    "            tokens_generated += 1\n",
    "\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "            states_value = [h, c]\n",
    "\n",
    "    print(f\"Decoded Sentence: {decoded_sentence.strip()}\")\n",
    "    return decoded_sentence.strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c524f-4f67-4cb3-8ef1-324660822b28",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "c7328971-b016-4854-bcea-e49fffbd2336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Is she okay?\n",
      "Processed Text: sofs okay eofs\n",
      "Input Sequence: [[ 1 38  2  0  0  0  0  0  0  0]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Sampled Token Index: 2\n",
      "Sampled Char: eofs\n",
      "Decoded Sentence: \n",
      "Bot: \n",
      "User: How are you feeling today?\n",
      "Processed Text: sofs feeling today eofs\n",
      "Input Sequence: [[  1 339 226   2   0   0   0   0   0   0]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Sampled Token Index: 2\n",
      "Sampled Char: eofs\n",
      "Decoded Sentence: \n",
      "Bot: \n",
      "User: Hi there!\n",
      "Processed Text: sofs hi eofs\n",
      "Input Sequence: [[  1 258   2   0   0   0   0   0   0   0]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Sampled Token Index: 2\n",
      "Sampled Char: eofs\n",
      "Decoded Sentence: \n",
      "Bot: \n",
      "User: Can you tell me the weather forecast for today?\n",
      "Processed Text: sofs tell weather forecast today eofs\n",
      "Input Sequence: [[   1   22 1134  226    2    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Sampled Token Index: 2\n",
      "Sampled Char: eofs\n",
      "Decoded Sentence: \n",
      "Bot: \n",
      "User: I think artificial intelligence is changing the world.\n",
      "Processed Text: sofs think artificial intelligence changing world eofs\n",
      "Input Sequence: [[   1    9 7217 1759 2191  147    2    0    0    0]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Sampled Token Index: 2\n",
      "Sampled Char: eofs\n",
      "Decoded Sentence: \n",
      "Bot: \n",
      "User: Any good movie recommendations?\n",
      "Processed Text: sofs good movie recommendation eofs\n",
      "Input Sequence: [[   1   19  350 5274    2    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Sampled Token Index: 2\n",
      "Sampled Char: eofs\n",
      "Decoded Sentence: \n",
      "Bot: \n",
      "User: What do you mean by that?\n",
      "Processed Text: sofs mean eofs\n",
      "Input Sequence: [[ 1 32  2  0  0  0  0  0  0  0]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Sampled Token Index: 2\n",
      "Sampled Char: eofs\n",
      "Decoded Sentence: \n",
      "Bot: \n",
      "User: I'm feeling really sad today.\n",
      "Processed Text: sofs feeling really sad today eofs\n",
      "Input Sequence: [[   1  339   40 1062  226    2    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Sampled Token Index: 2\n",
      "Sampled Char: eofs\n",
      "Decoded Sentence: \n",
      "Bot: \n",
      "User: What are the implications of quantum computing on cybersecurity?\n",
      "Processed Text: sofs implication quantum computing cybersecurity eofs\n",
      "Input Sequence: [[   1 6031 6360    2    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Sampled Token Index: 2\n",
      "Sampled Char: eofs\n",
      "Decoded Sentence: \n",
      "Bot: \n",
      "User: Why did the chicken cross the road?\n",
      "Processed Text: sofs chicken cross road eofs\n",
      "Input Sequence: [[  1 986 952 564   2   0   0   0   0   0]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Sampled Token Index: 2\n",
      "Sampled Char: eofs\n",
      "Decoded Sentence: \n",
      "Bot: \n",
      "User: Can you explain the plot of The Matrix?\n",
      "Processed Text: sofs explain plot matrix eofs\n",
      "Input Sequence: [[   1  539 3577 4089    2    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Sampled Token Index: 2\n",
      "Sampled Char: eofs\n",
      "Decoded Sentence: \n",
      "Bot: \n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "print(\"User: Is she okay?\")\n",
    "print(\"Bot:\", generate_response('she okay?'))\n",
    "\n",
    "print(\"User: How are you feeling today?\")\n",
    "print(\"Bot:\", generate_response('How are you feeling today?'))\n",
    "\n",
    "print(\"User: Hi there!\")\n",
    "print(\"Bot:\", generate_response('Hi there!'))\n",
    "\n",
    "print(\"User: Can you tell me the weather forecast for today?\")\n",
    "print(\"Bot:\", generate_response('Can you tell me the weather forecast for today?'))\n",
    "\n",
    "print(\"User: I think artificial intelligence is changing the world.\")\n",
    "print(\"Bot:\", generate_response('I think artificial intelligence is changing the world.'))\n",
    "\n",
    "print(\"User: Any good movie recommendations?\")\n",
    "print(\"Bot:\", generate_response('Any good movie recommendations?'))\n",
    "\n",
    "print(\"User: What do you mean by that?\")\n",
    "print(\"Bot:\", generate_response('What do you mean by that?'))\n",
    "\n",
    "print(\"User: I'm feeling really sad today.\")\n",
    "print(\"Bot:\", generate_response(\"I'm feeling really sad today.\"))\n",
    "\n",
    "print(\"User: What are the implications of quantum computing on cybersecurity?\")\n",
    "print(\"Bot:\", generate_response('What are the implications of quantum computing on cybersecurity?'))\n",
    "\n",
    "print(\"User: Why did the chicken cross the road?\")\n",
    "print(\"Bot:\", generate_response('Why did the chicken cross the road?'))\n",
    "\n",
    "print(\"User: Can you explain the plot of The Matrix?\")\n",
    "print(\"Bot:\", generate_response('Can you explain the plot of The Matrix?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e598c-98e8-4336-8e47-015473ec4dde",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "d68f9dcc-f8b8-404b-904e-726bc55d3ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_46_layer_call_fn, lstm_cell_46_layer_call_and_return_conditional_losses, lstm_cell_47_layer_call_fn, lstm_cell_47_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tomui\\Desktop\\capstone_project\\data\\s2s_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tomui\\Desktop\\capstone_project\\data\\s2s_model\\assets\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "file_path_tf = os.path.join(data_dir, 's2s_model')\n",
    "model.save(file_path_tf, save_format='tf')\n",
    "file_path_h5 = os.path.join(data_dir, 's2s_model.h5')\n",
    "model.save(file_path_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "dfbd8d24-ef65-4b31-beab-89aa0d6bfe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# # Assume you have already defined your model architecture\n",
    "# vocab_size = len(tokenizer.word_index) + 1\n",
    "# encoder_inputs = Input(shape=(None,))\n",
    "# encoder_embedding = Embedding(vocab_size, 100, mask_zero=True)(encoder_inputs)\n",
    "# encoder_outputs, state_h, state_c = LSTM(256, return_state=True)(encoder_embedding)\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# decoder_inputs = Input(shape=(None,))\n",
    "# decoder_embedding = Embedding(vocab_size, 100, mask_zero=True)(decoder_inputs)\n",
    "# decoder_lstm = LSTM(256, return_sequences=True, return_state=False)(decoder_embedding, initial_state=encoder_states)\n",
    "# decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "# output = decoder_dense(decoder_outputs)\n",
    "\n",
    "# model = Model([encoder_inputs, decoder_inputs], output)\n",
    "# model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Setup the ModelCheckpoint callback to save the model after each epoch\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     'path/to/save/model_epoch_{epoch:02d}.h5',\n",
    "#     save_weights_only=False,  # Set to True if you only need to save the weights, not the full model\n",
    "#     save_freq='epoch',  # Save after each epoch\n",
    "#     verbose=1  # Logs a message each time the model is saved\n",
    "# )\n",
    "\n",
    "# # Train the model with the checkpoint callback\n",
    "# model.fit(\n",
    "#     [input_train, decoder_input_train], \n",
    "#     target_train,\n",
    "#     validation_data=([input_val, decoder_input_val], target_val),\n",
    "#     epochs=10,  # Or however many epochs you need\n",
    "#     batch_size=64,\n",
    "#     callbacks=[checkpoint_callback]  # Pass the callback to the fit method\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
