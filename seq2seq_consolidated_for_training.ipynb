{"cells":[{"cell_type":"markdown","id":"b0ZiOK0MWE7d","metadata":{"id":"b0ZiOK0MWE7d"},"source":["## GPU info"]},{"cell_type":"code","execution_count":1,"id":"bhvFI7ztVLRy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhvFI7ztVLRy","outputId":"e4fb02b2-7ebf-4f3e-b2a8-f9f189a25c47","executionInfo":{"status":"ok","timestamp":1715927490489,"user_tz":-180,"elapsed":420,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri May 17 06:31:29 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n","| N/A   35C    P8              11W /  72W |      1MiB / 23034MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RMth1TfbAys6","executionInfo":{"status":"ok","timestamp":1715927517410,"user_tz":-180,"elapsed":23496,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}},"outputId":"766cb4f5-edfa-4cd7-ad09-825604e4c786"},"id":"RMth1TfbAys6","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"id":"db509470-cb51-4c21-84ca-5f928073d68e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"db509470-cb51-4c21-84ca-5f928073d68e","outputId":"95b90920-4333-45db-f52c-0f88f1ec6a5e","executionInfo":{"status":"ok","timestamp":1715927650106,"user_tz":-180,"elapsed":4075,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Device Name: /device:GPU:0\n","Memory Limit: 21991653376 bytes\n","Description: device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"]}],"source":["# Check if GPU is available\n","from tensorflow.python.client import device_lib\n","\n","def get_gpu_details():\n","    devices = device_lib.list_local_devices()\n","    for device in devices:\n","        if device.device_type == 'GPU':\n","            print(f\"Device Name: {device.name}\")\n","            print(f\"Memory Limit: {device.memory_limit} bytes\")\n","            print(f\"Description: {device.physical_device_desc}\")\n","\n","get_gpu_details()\n"]},{"cell_type":"code","execution_count":4,"id":"6648d492-f4e0-40a8-a3ff-012fa0a0d293","metadata":{"id":"6648d492-f4e0-40a8-a3ff-012fa0a0d293","executionInfo":{"status":"ok","timestamp":1715927650106,"user_tz":-180,"elapsed":4,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[],"source":["# !pip install spacy\n","# !python -m spacy download en_core_web_sm"]},{"cell_type":"code","execution_count":5,"id":"8a0af574-6748-467b-8ba6-4da51794c5b9","metadata":{"id":"8a0af574-6748-467b-8ba6-4da51794c5b9","executionInfo":{"status":"ok","timestamp":1715927650106,"user_tz":-180,"elapsed":3,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[],"source":["# !pip install pyarrow"]},{"cell_type":"code","execution_count":6,"id":"7e4e2a98-f1d4-4f72-b95e-6a75f457e8e8","metadata":{"id":"7e4e2a98-f1d4-4f72-b95e-6a75f457e8e8","executionInfo":{"status":"ok","timestamp":1715927650106,"user_tz":-180,"elapsed":2,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[],"source":["# !pip install fastparquet"]},{"cell_type":"code","execution_count":71,"id":"b29568f1-df35-42d2-85e3-cb2eee0cab2b","metadata":{"id":"b29568f1-df35-42d2-85e3-cb2eee0cab2b","executionInfo":{"status":"ok","timestamp":1715930793574,"user_tz":-180,"elapsed":238,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[],"source":["import os\n","\n","import re\n","import string\n","import unicodedata\n","import nltk\n","# import spacy\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, Concatenate, Layer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","\n","from tensorflow.keras.models import load_model\n","\n","import pickle"]},{"cell_type":"code","execution_count":72,"id":"y5srV6bjOpFb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5srV6bjOpFb","outputId":"b74db1e8-1afe-4348-be1a-23c150492567","executionInfo":{"status":"ok","timestamp":1715930801381,"user_tz":-180,"elapsed":231,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["# Download necessary NLTK resources\n","nltk.download('punkt')  # Tokenizer\n","nltk.download('wordnet')  # Lemmatizer\n","nltk.download('stopwords')  # Stopwords\n","nltk.download('omw-1.4') # Ensures multilingual contexts\n","\n","# Stopwords list\n","stop_words = set(stopwords.words('english'))\n","\n","# Initialize the lemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","initial_preprocessing = True\n","\n","# # Load spaCy's English NLP model\n","# nlp = spacy.load('en_core_web_sm')"]},{"cell_type":"markdown","id":"f5150d2f-999d-45ad-b2f2-b9b65b883e89","metadata":{"id":"f5150d2f-999d-45ad-b2f2-b9b65b883e89"},"source":["## Create prepocessing functions for initial text and later response generation preprocessing"]},{"cell_type":"code","execution_count":73,"id":"f0e8f237-5274-43ee-8ac2-964dd9214ae5","metadata":{"id":"f0e8f237-5274-43ee-8ac2-964dd9214ae5","executionInfo":{"status":"ok","timestamp":1715930818326,"user_tz":-180,"elapsed":238,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[],"source":["def normalize_text(text: str) -> str:\n","    # Normalize Unicode string to NFKD form, remove non-ASCII characters, and then decode it back to a UTF-8 string\n","    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Add a space before any punctuation mark (., !, or ?)\n","    text = re.sub(r\"([.!?])\", r\" \\1\", text)\n","    # Handle contractions correctly by not adding space before apostrophe\n","    text = re.sub(r\"(\\b\\w+)'(d|s|t|ll|ve|re)\", r\"\\1'\\2\", text)\n","    # Replace any sequence of characters that are not letters, keep basic punctuation\n","    text = re.sub(r\"[^a-z.,'!? ]\", ' ', text)\n","    # Replace any sequence of whitespace characters with a single space and remove leading and trailing whitespace\n","    text = re.sub(r\"\\s+\", r\" \", text).strip()\n","    return text\n","\n","def remove_names(text: str) -> str:\n","    # Use spaCy to detect and remove names from the text\n","    doc = nlp(text)\n","    filtered_text = ' '.join([token.text for token in doc if token.ent_type_ != 'PERSON']) # Takes really long time, exlude from chatbot input preprocessing\n","    return filtered_text\n","\n","def preprocess_text(text: str) -> str:\n","    # Normalize text\n","    text = normalize_text(text)\n","    # Remove names using spaCy's NER\n","    if initial_preprocessing:\n","        text = remove_names(text)\n","    # # Remove punctuation\n","    # text = text.translate(str.maketrans('', '', string.punctuation))\n","    # Remove stopwords and tokenize\n","    # words = word_tokenize(text) # More intelligent splitting\n","    # filtered_words = [word for word in words if word not in stop_words]\n","    # # Lemmatize words\n","    # lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n","    # Add <SOS> and <EOS> tokens, and join the list into a single string\n","    # return ' '.join(['sofs'] + lemmatized_words + ['eofs'])\n","    return 'sofs ' + text + ' eofs' # Chosen ['sofs', 'eofs'] because tokenizer removes everthing what is in <> or || and are not in dataset vocabulary"]},{"cell_type":"markdown","id":"e332df38-04f5-4261-a544-786538749051","metadata":{"id":"e332df38-04f5-4261-a544-786538749051"},"source":["## Load the Tokenizer"]},{"cell_type":"code","execution_count":74,"id":"3e087632-daab-4026-862e-0c7b33ebe0fa","metadata":{"id":"3e087632-daab-4026-862e-0c7b33ebe0fa","executionInfo":{"status":"ok","timestamp":1715930847502,"user_tz":-180,"elapsed":235,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[],"source":["# Load the tokenizer from file\n","data_dir = os.path.join(os.getcwd(), 'data')\n","tokenizer_path = os.path.join(data_dir, 'tokenizer.pickle')\n","with open(tokenizer_path, 'rb') as handle:\n","    tokenizer = pickle.load(handle)"]},{"cell_type":"code","execution_count":75,"id":"4c78c771-eb63-499b-9f47-483d825bf9db","metadata":{"id":"4c78c771-eb63-499b-9f47-483d825bf9db","outputId":"fcf16841-268a-4cd7-fa5f-c7421130f086","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715930854503,"user_tz":-180,"elapsed":235,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1 2\n"]}],"source":["print(tokenizer.word_index['sofs'], tokenizer.word_index['eofs']) # Checking if <start> and <end> tokens are in index (vocabulary)"]},{"cell_type":"code","execution_count":76,"id":"eed2bb9f-a5db-4bf1-962d-810dabe5247c","metadata":{"id":"eed2bb9f-a5db-4bf1-962d-810dabe5247c","outputId":"de896c51-7568-45df-9c84-2f925d841fae","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715930859778,"user_tz":-180,"elapsed":255,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[('sofs', 304713), ('eofs', 304713), ('you', 148729), ('i', 142169), ('the', 99290), ('to', 80761), ('a', 71534), (\"'s\", 66252), ('it', 66206), (\"n't\", 55106)]\n","[('nihilistic', 1), ('freelancing', 1), ('gatherer', 1), ('overview', 1), ('retardant', 1), ('deploys', 1), ('beastie', 1), ('ozzfest', 1), ('russkie', 1), ('shavers', 1), ('mersh', 1), ('slovo', 1), ('dawning', 1), ('tshirt', 1), ('dishonorably', 1), ('vandals', 1), ('grozny', 1), ('lamborghini', 1), ('genoa', 1), ('pizda', 1), ('filament', 1), ('replicate', 1), ('solider', 1), ('secaucus', 1), ('athletics', 1), ('herded', 1), ('wolverine', 1), ('absorbs', 1), ('definitively', 1), ('poppycock', 1), ('rumous', 1), ('disinfectant', 1), ('celery', 1), ('cerebrum', 1), ('unashamedly', 1), ('dien', 1), ('gerhart', 1), ('mending', 1), ('galvanism', 1), ('equalize', 1), ('cerebrospinal', 1), ('madein', 1), ('froderick', 1), ('blindingly', 1), ('desserts', 1), ('impossibilities', 1), ('recesses', 1), ('ascend', 1), ('thunders', 1), ('kites', 1), ('cookbooks', 1), ('diagnostician', 1), ('sockers', 1), ('fockers', 1), ('fredereck', 1), ('frodereck', 1), ('fronkon', 1), ('ereck', 1), ('dereck', 1), ('mmmmmmmmmm', 1), ('mmmmmmmmmmmmmmmmmmmmmmmmm', 1), ('pah', 1), ('trouper', 1), (\"diff'rent\", 1), ('mmmmmmmmmmm', 1), ('mmmmmmmmmmmmmnnnnnnmmmmmmmm', 1), ('transylvanian', 1), ('apfelstrudel', 1), ('mmmmmmmmmmmmmmm', 1), ('fuchsmachen', 1), ('liebe', 1), ('danc', 1), ('ul', 1), ('tra', 1), ('sacral', 1), ('minuteness', 1), ('schwanzstucker', 1), ('grrrhmmnnnjkjmmmnn', 1), ('roughhousing', 1), ('foooooood', 1), ('dooty', 1), ('lifebuoy', 1), ('saij', 1), ('peifecl', 1), ('meseif', 1), ('wellington', 1), ('lorj', 1), ('cetshwayo', 1), ('manoeuvre', 1), ('indeedldid', 1), ('mylord', 1), ('itwas', 1), ('ofthe', 1), ('adc', 1), ('ofnatal', 1), ('subaltern', 1), ('horsemanship', 1), ('splendil', 1), ('impi', 1), ('basutos', 1)]\n"]}],"source":["# Top words in dictionary\n","from collections import OrderedDict\n","\n","# Sort the word_counts dictionary by frequency in descending order\n","sorted_word_counts = OrderedDict(sorted(tokenizer.word_counts.items(), key=lambda x: x[1], reverse=True))\n","\n","# Display the sorted word counts\n","print(list(sorted_word_counts.items())[:10])\n","print(list(sorted_word_counts.items())[-100:])"]},{"cell_type":"markdown","id":"01444ef2-087e-4f5e-9a6a-26c9c63c9b8d","metadata":{"id":"01444ef2-087e-4f5e-9a6a-26c9c63c9b8d"},"source":["## Load the Data"]},{"cell_type":"code","execution_count":77,"id":"e3699bc1-d5ec-41d6-ba0f-de02b3905615","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"e3699bc1-d5ec-41d6-ba0f-de02b3905615","outputId":"165f6fd8-1a49-4328-8b33-ed489ba8fb45","tags":[],"executionInfo":{"status":"ok","timestamp":1715930878877,"user_tz":-180,"elapsed":519,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  ID_Input                             Padded_Input_Sequences ID_Response  \\\n","0    L1044    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 37, 11, 6, 2]       L1045   \n","1     L984   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 51, 111, 2]        L985   \n","2     L924    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 897, 2]        L925   \n","3     L871     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 32, 2]        L872   \n","4     L870  [1, 4, 24, 671, 3, 25, 55, 464, 3, 38, 711, 21...        L871   \n","5     L868    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 224, 3, 2]        L869   \n","6     L867  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 15, 74, 309, 2]        L868   \n","7     L866  [0, 0, 0, 1, 4, 772, 3, 80, 44, 6, 5, 74, 309,...        L867   \n","8     L864  [0, 0, 0, 0, 1, 17, 21, 6852, 2510, 4, 24, 40,...        L865   \n","9     L863  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 15, 1075, 2]        L864   \n","\n","                             Padded_Target_Sequences  \n","0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 37, 11, 31, 2]  \n","1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 347, 46, 2]  \n","2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 95, 8, 63, 2]  \n","3  [0, 0, 1, 111, 3, 26, 118, 117, 129, 6, 650, 5...  \n","4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 32, 2]  \n","5  [0, 0, 0, 0, 0, 0, 0, 0, 1, 40, 29, 885, 14, 9...  \n","6    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 224, 3, 2]  \n","7  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 15, 74, 309, 2]  \n","8  [0, 1, 210, 197, 49, 4, 102, 6, 226, 57, 115, ...  \n","9  [0, 0, 0, 0, 1, 17, 21, 6852, 2510, 4, 24, 40,...  "],"text/html":["\n","  <div id=\"df-0e85a42f-9771-4d24-8833-1090548da154\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID_Input</th>\n","      <th>Padded_Input_Sequences</th>\n","      <th>ID_Response</th>\n","      <th>Padded_Target_Sequences</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>L1044</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 37, 11, 6, 2]</td>\n","      <td>L1045</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 37, 11, 31, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>L984</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 51, 111, 2]</td>\n","      <td>L985</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 347, 46, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>L924</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 897, 2]</td>\n","      <td>L925</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 95, 8, 63, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>L871</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 32, 2]</td>\n","      <td>L872</td>\n","      <td>[0, 0, 1, 111, 3, 26, 118, 117, 129, 6, 650, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>L870</td>\n","      <td>[1, 4, 24, 671, 3, 25, 55, 464, 3, 38, 711, 21...</td>\n","      <td>L871</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 32, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>L868</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 224, 3, 2]</td>\n","      <td>L869</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 40, 29, 885, 14, 9...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>L867</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 15, 74, 309, 2]</td>\n","      <td>L868</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 224, 3, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>L866</td>\n","      <td>[0, 0, 0, 1, 4, 772, 3, 80, 44, 6, 5, 74, 309,...</td>\n","      <td>L867</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 15, 74, 309, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>L864</td>\n","      <td>[0, 0, 0, 0, 1, 17, 21, 6852, 2510, 4, 24, 40,...</td>\n","      <td>L865</td>\n","      <td>[0, 1, 210, 197, 49, 4, 102, 6, 226, 57, 115, ...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>L863</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 15, 1075, 2]</td>\n","      <td>L864</td>\n","      <td>[0, 0, 0, 0, 1, 17, 21, 6852, 2510, 4, 24, 40,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e85a42f-9771-4d24-8833-1090548da154')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0e85a42f-9771-4d24-8833-1090548da154 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0e85a42f-9771-4d24-8833-1090548da154');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-65fbec24-3a57-4c47-a771-cb563da7862e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65fbec24-3a57-4c47-a771-cb563da7862e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-65fbec24-3a57-4c47-a771-cb563da7862e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"training_data_final"}},"metadata":{},"execution_count":77}],"source":["# Loading the DataFrame\n","file_path_parquet = os.path.join(data_dir, 'training_df_s2s.parquet')\n","training_data_final = pd.read_parquet(file_path_parquet)\n","\n","training_data_final.head(10)"]},{"cell_type":"code","source":["# len(training_data_final)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQiXPEUXiKUG","executionInfo":{"status":"ok","timestamp":1715927652744,"user_tz":-180,"elapsed":5,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}},"outputId":"3f38ae61-e2c3-4615-b656-0705c2eab67c"},"id":"fQiXPEUXiKUG","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["221616"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# training_data_final = training_data_final.head(20000)"],"metadata":{"id":"hHqj2Drvjc0b","executionInfo":{"status":"ok","timestamp":1715927652744,"user_tz":-180,"elapsed":4,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"id":"hHqj2Drvjc0b","execution_count":15,"outputs":[]},{"cell_type":"code","source":["# len(training_data_final)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlLY_UYFjnZt","executionInfo":{"status":"ok","timestamp":1715927652744,"user_tz":-180,"elapsed":4,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}},"outputId":"e5597a1a-0a4e-4916-838e-ace7c92b1fc3"},"id":"UlLY_UYFjnZt","execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20000"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","id":"52e65d15-20cc-45ed-a490-f9e04ec7330a","metadata":{"id":"52e65d15-20cc-45ed-a490-f9e04ec7330a"},"source":["# Encoder-decoder architecture with Attention Layer"]},{"cell_type":"code","execution_count":78,"id":"9f7bb8ea-317a-473d-b081-fb3c6e425128","metadata":{"id":"9f7bb8ea-317a-473d-b081-fb3c6e425128","executionInfo":{"status":"ok","timestamp":1715930901902,"user_tz":-180,"elapsed":247,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, Concatenate, Layer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf"]},{"cell_type":"markdown","id":"0fc79e52-4f84-48ba-9313-dc2188467df0","metadata":{"id":"0fc79e52-4f84-48ba-9313-dc2188467df0"},"source":["## Attention Layer"]},{"cell_type":"code","execution_count":79,"id":"7a7cdf18-2ada-433a-a343-b06501abec51","metadata":{"id":"7a7cdf18-2ada-433a-a343-b06501abec51","executionInfo":{"status":"ok","timestamp":1715930905361,"user_tz":-180,"elapsed":245,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[],"source":["class Attention(Layer):\n","    def __init__(self, units, **kwargs):\n","        super(Attention, self).__init__(**kwargs)\n","        self.units = units\n","        self.W1 = Dense(units)\n","        self.W2 = Dense(units)\n","        self.V = Dense(1)\n","\n","    def call(self, query, values):\n","        query_with_time_axis = tf.expand_dims(query, 1)\n","        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(query_with_time_axis)))\n","        attention_weights = tf.nn.softmax(score, axis=1)\n","        context_vector = attention_weights * values\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","        return context_vector, attention_weights\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"units\": self.units\n","        })\n","        return config\n","\n","class AttentionLayer(Layer):\n","    def __init__(self, units, **kwargs):\n","        super(AttentionLayer, self).__init__(**kwargs)\n","        self.units = units\n","        self.attention = Attention(units)\n","\n","    def call(self, inputs):\n","        decoder_outputs, encoder_outputs = inputs\n","        batch_size = tf.shape(decoder_outputs)[0]\n","        sequence_length = tf.shape(decoder_outputs)[1]\n","        hidden_size = tf.shape(decoder_outputs)[2]\n","\n","        # Tile encoder_outputs to match the batch and sequence length\n","        encoder_outputs = tf.tile(tf.expand_dims(encoder_outputs, 1), [1, sequence_length, 1, 1])\n","        encoder_outputs = tf.reshape(encoder_outputs, [batch_size * sequence_length, -1, hidden_size])\n","\n","        # Flatten decoder_outputs to match encoder outputs\n","        decoder_outputs = tf.reshape(decoder_outputs, [batch_size * sequence_length, hidden_size])\n","\n","        # Compute attention context vector\n","        context_vector, attention_weights = self.attention(decoder_outputs, encoder_outputs)\n","        context_vector = tf.reshape(context_vector, [batch_size, sequence_length, hidden_size])\n","\n","        return context_vector\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"units\": self.units\n","        })\n","        return config\n"]},{"cell_type":"markdown","id":"3d0c2771-8673-477e-9c69-36fe31161d4b","metadata":{"id":"3d0c2771-8673-477e-9c69-36fe31161d4b"},"source":["## Define the Model"]},{"cell_type":"code","execution_count":80,"id":"24a19eb1-be04-4468-8d62-29bffe7c1524","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24a19eb1-be04-4468-8d62-29bffe7c1524","executionInfo":{"status":"ok","timestamp":1715930912704,"user_tz":-180,"elapsed":3449,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}},"outputId":"2bddb0a9-c382-403f-9f6b-d74ffebd25d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_11\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_23 (InputLayer)       [(None, None)]               0         []                            \n","                                                                                                  \n"," embedding_7 (Embedding)     (None, None, 50)             2379000   ['input_23[0][0]']            \n","                                                                                                  \n"," input_24 (InputLayer)       [(None, None)]               0         []                            \n","                                                                                                  \n"," bidirectional_1 (Bidirecti  [(None, None, 512),          628736    ['embedding_7[0][0]']         \n"," onal)                        (None, 256),                                                        \n","                              (None, 256),                                                        \n","                              (None, 256),                                                        \n","                              (None, 256)]                                                        \n","                                                                                                  \n"," embedding_8 (Embedding)     (None, None, 50)             2379000   ['input_24[0][0]']            \n","                                                                                                  \n"," concatenate_8 (Concatenate  (None, 512)                  0         ['bidirectional_1[0][1]',     \n"," )                                                                   'bidirectional_1[0][3]']     \n","                                                                                                  \n"," concatenate_9 (Concatenate  (None, 512)                  0         ['bidirectional_1[0][2]',     \n"," )                                                                   'bidirectional_1[0][4]']     \n","                                                                                                  \n"," lstm_3 (LSTM)               [(None, None, 512),          1153024   ['embedding_8[0][0]',         \n","                              (None, 512),                           'concatenate_8[0][0]',       \n","                              (None, 512)]                           'concatenate_9[0][0]']       \n","                                                                                                  \n"," attention_layer_1 (Attenti  (None, None, 512)            10271     ['lstm_3[0][0]',              \n"," onLayer)                                                            'bidirectional_1[0][0]']     \n","                                                                                                  \n"," concatenate_10 (Concatenat  (None, None, 1024)           0         ['attention_layer_1[0][0]',   \n"," e)                                                                  'lstm_3[0][0]']              \n","                                                                                                  \n"," dense_13 (Dense)            (None, None, 47580)          4876950   ['concatenate_10[0][0]']      \n","                                                          0                                       \n","                                                                                                  \n","==================================================================================================\n","Total params: 55319531 (211.03 MB)\n","Trainable params: 55319531 (211.03 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["input_sequences = np.array(training_data_final['Padded_Input_Sequences'].tolist())\n","target_sequences = np.array(training_data_final['Padded_Target_Sequences'].tolist())\n","\n","# Splitting the data into training and validation sets\n","input_train, input_val, target_train, target_val = train_test_split(input_sequences, target_sequences, test_size=0.1, random_state=22)\n","\n","# Building the model\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","# Encoder\n","encoder_inputs = Input(shape=(None,))\n","encoder_embedding = Embedding(vocab_size, 50, mask_zero=True)(encoder_inputs)\n","encoder_lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(\n","    LSTM(256, return_state=True, return_sequences=True))(encoder_embedding)\n","encoder_states = [Concatenate()([forward_h, backward_h]), Concatenate()([forward_c, backward_c])]\n","encoder_outputs = encoder_lstm\n","\n","# Attention Mechanism\n","attention_units = 10\n","attention_layer = AttentionLayer(attention_units)\n","\n","# Decoder\n","decoder_inputs = Input(shape=(None,))\n","decoder_embedding = Embedding(vocab_size, 50, mask_zero=True)(decoder_inputs)\n","decoder_lstm = LSTM(512, return_sequences=True, return_state=True)\n","decoder_lstm_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n","\n","# Apply attention to each time step in the decoder\n","context_vectors = attention_layer([decoder_lstm_outputs, encoder_outputs])\n","\n","decoder_concat_input = Concatenate(axis=-1)([context_vectors, decoder_lstm_outputs])\n","decoder_dense = Dense(vocab_size, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_concat_input)\n","\n","# Main Model\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","optimizer = Adam(learning_rate=0.001)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"markdown","id":"d3ca75d8-20d4-4508-8510-41998137ade6","metadata":{"id":"d3ca75d8-20d4-4508-8510-41998137ade6"},"source":["## Load the Model"]},{"cell_type":"code","execution_count":81,"id":"86055360-706e-4f44-9181-311b9029488f","metadata":{"id":"86055360-706e-4f44-9181-311b9029488f","executionInfo":{"status":"ok","timestamp":1715930930348,"user_tz":-180,"elapsed":244,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[],"source":["# from tensorflow.keras.models import load_model\n","\n","# data_dir = os.path.join(os.getcwd(), 'data')\n","# file_path_h5 = os.path.join(data_dir, 's2s_model.h5')\n","\n","# # Load the model\n","# custom_objects = {'Attention': Attention, 'AttentionLayer': AttentionLayer}\n","# model = load_model(file_path_h5, custom_objects=custom_objects)\n","# model.summary()"]},{"cell_type":"code","source":["# from tensorflow.keras.models import load_model\n","\n","# # Load the model\n","# model_path = 's2s_modelmodel_checkpoint_epoch_12.h5'\n","# custom_objects = {'Attention': Attention, 'AttentionLayer': AttentionLayer}\n","# model = load_model(model_path, custom_objects=custom_objects)\n","\n","# # Summary of the loaded model\n","# model.summary()\n"],"metadata":{"id":"zxYevsdOiA0t","executionInfo":{"status":"ok","timestamp":1715927953337,"user_tz":-180,"elapsed":3,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"id":"zxYevsdOiA0t","execution_count":34,"outputs":[]},{"cell_type":"markdown","id":"504957c2-6f60-45b0-b1f0-5729778d1159","metadata":{"id":"504957c2-6f60-45b0-b1f0-5729778d1159"},"source":["## Train the Model"]},{"cell_type":"code","execution_count":35,"id":"b4990b26-62da-4563-af60-d4ee2faa8007","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4990b26-62da-4563-af60-d4ee2faa8007","outputId":"c38e6aae-5ce4-40ac-a980-59bb8bdc5488","executionInfo":{"status":"ok","timestamp":1715929811681,"user_tz":-180,"elapsed":1858347,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","282/282 [==============================] - 62s 192ms/step - loss: 2.7247 - accuracy: 0.3890 - val_loss: 5.6891 - val_accuracy: 0.1750\n","Epoch 2/50\n","282/282 [==============================] - 38s 134ms/step - loss: 2.6131 - accuracy: 0.4092 - val_loss: 5.7660 - val_accuracy: 0.1713\n","Epoch 3/50\n","282/282 [==============================] - 37s 131ms/step - loss: 2.4985 - accuracy: 0.4299 - val_loss: 5.8464 - val_accuracy: 0.1700\n","Epoch 4/50\n","282/282 [==============================] - 37s 130ms/step - loss: 2.3913 - accuracy: 0.4509 - val_loss: 5.9223 - val_accuracy: 0.1675\n","Epoch 5/50\n","282/282 [==============================] - 37s 130ms/step - loss: 2.2903 - accuracy: 0.4714 - val_loss: 5.9870 - val_accuracy: 0.1700\n","Epoch 6/50\n","282/282 [==============================] - 37s 131ms/step - loss: 2.1889 - accuracy: 0.4917 - val_loss: 6.0699 - val_accuracy: 0.1644\n","Epoch 7/50\n","282/282 [==============================] - 36s 129ms/step - loss: 2.0880 - accuracy: 0.5137 - val_loss: 6.1459 - val_accuracy: 0.1579\n","Epoch 8/50\n","282/282 [==============================] - 37s 131ms/step - loss: 1.9942 - accuracy: 0.5344 - val_loss: 6.2280 - val_accuracy: 0.1602\n","Epoch 9/50\n","282/282 [==============================] - 37s 130ms/step - loss: 1.9207 - accuracy: 0.5495 - val_loss: 6.3165 - val_accuracy: 0.1551\n","Epoch 10/50\n","282/282 [==============================] - 37s 130ms/step - loss: 1.8343 - accuracy: 0.5703 - val_loss: 6.3926 - val_accuracy: 0.1532\n","Epoch 11/50\n","282/282 [==============================] - 37s 130ms/step - loss: 1.7434 - accuracy: 0.5916 - val_loss: 6.4823 - val_accuracy: 0.1505\n","Epoch 12/50\n","282/282 [==============================] - 37s 130ms/step - loss: 1.6612 - accuracy: 0.6112 - val_loss: 6.5815 - val_accuracy: 0.1526\n","Epoch 13/50\n","282/282 [==============================] - 37s 133ms/step - loss: 1.5730 - accuracy: 0.6314 - val_loss: 6.6507 - val_accuracy: 0.1498\n","Epoch 14/50\n","282/282 [==============================] - 37s 130ms/step - loss: 1.4887 - accuracy: 0.6530 - val_loss: 6.7566 - val_accuracy: 0.1461\n","Epoch 15/50\n","282/282 [==============================] - 36s 129ms/step - loss: 1.4119 - accuracy: 0.6723 - val_loss: 6.8552 - val_accuracy: 0.1490\n","Epoch 16/50\n","282/282 [==============================] - 37s 130ms/step - loss: 1.3405 - accuracy: 0.6899 - val_loss: 6.9211 - val_accuracy: 0.1450\n","Epoch 17/50\n","282/282 [==============================] - 37s 130ms/step - loss: 1.2699 - accuracy: 0.7077 - val_loss: 7.0171 - val_accuracy: 0.1404\n","Epoch 18/50\n","282/282 [==============================] - 37s 131ms/step - loss: 1.2033 - accuracy: 0.7246 - val_loss: 7.1233 - val_accuracy: 0.1424\n","Epoch 19/50\n","282/282 [==============================] - 37s 130ms/step - loss: 1.1420 - accuracy: 0.7402 - val_loss: 7.2129 - val_accuracy: 0.1400\n","Epoch 20/50\n","282/282 [==============================] - 37s 130ms/step - loss: 1.0911 - accuracy: 0.7525 - val_loss: 7.2978 - val_accuracy: 0.1408\n","Epoch 21/50\n","282/282 [==============================] - 37s 131ms/step - loss: 1.0388 - accuracy: 0.7659 - val_loss: 7.4119 - val_accuracy: 0.1383\n","Epoch 22/50\n","282/282 [==============================] - 37s 130ms/step - loss: 0.9621 - accuracy: 0.7870 - val_loss: 7.5129 - val_accuracy: 0.1362\n","Epoch 23/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.8995 - accuracy: 0.8032 - val_loss: 7.6216 - val_accuracy: 0.1319\n","Epoch 24/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.8471 - accuracy: 0.8170 - val_loss: 7.7372 - val_accuracy: 0.1337\n","Epoch 25/50\n","282/282 [==============================] - 36s 128ms/step - loss: 0.7963 - accuracy: 0.8302 - val_loss: 7.8250 - val_accuracy: 0.1312\n","Epoch 26/50\n","282/282 [==============================] - 37s 130ms/step - loss: 0.7489 - accuracy: 0.8419 - val_loss: 7.9457 - val_accuracy: 0.1355\n","Epoch 27/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.7100 - accuracy: 0.8514 - val_loss: 8.0133 - val_accuracy: 0.1296\n","Epoch 28/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.6667 - accuracy: 0.8627 - val_loss: 8.1305 - val_accuracy: 0.1288\n","Epoch 29/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.6181 - accuracy: 0.8749 - val_loss: 8.2233 - val_accuracy: 0.1311\n","Epoch 30/50\n","282/282 [==============================] - 37s 130ms/step - loss: 0.5885 - accuracy: 0.8825 - val_loss: 8.3378 - val_accuracy: 0.1289\n","Epoch 31/50\n","282/282 [==============================] - 36s 128ms/step - loss: 0.5516 - accuracy: 0.8923 - val_loss: 8.4229 - val_accuracy: 0.1273\n","Epoch 32/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.5726 - accuracy: 0.8828 - val_loss: 8.4965 - val_accuracy: 0.1251\n","Epoch 33/50\n","282/282 [==============================] - 37s 130ms/step - loss: 0.5029 - accuracy: 0.9030 - val_loss: 8.5997 - val_accuracy: 0.1276\n","Epoch 34/50\n","282/282 [==============================] - 37s 130ms/step - loss: 0.4610 - accuracy: 0.9142 - val_loss: 8.7053 - val_accuracy: 0.1263\n","Epoch 35/50\n","282/282 [==============================] - 37s 130ms/step - loss: 0.4148 - accuracy: 0.9258 - val_loss: 8.8186 - val_accuracy: 0.1237\n","Epoch 36/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.3797 - accuracy: 0.9344 - val_loss: 8.9215 - val_accuracy: 0.1241\n","Epoch 37/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.3573 - accuracy: 0.9396 - val_loss: 9.0197 - val_accuracy: 0.1236\n","Epoch 38/50\n","282/282 [==============================] - 37s 130ms/step - loss: 0.3465 - accuracy: 0.9413 - val_loss: 9.1111 - val_accuracy: 0.1218\n","Epoch 39/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.3404 - accuracy: 0.9419 - val_loss: 9.1904 - val_accuracy: 0.1249\n","Epoch 40/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.3338 - accuracy: 0.9430 - val_loss: 9.2989 - val_accuracy: 0.1217\n","Epoch 41/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.3106 - accuracy: 0.9483 - val_loss: 9.3545 - val_accuracy: 0.1202\n","Epoch 42/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.2863 - accuracy: 0.9534 - val_loss: 9.4751 - val_accuracy: 0.1221\n","Epoch 43/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.2676 - accuracy: 0.9575 - val_loss: 9.5538 - val_accuracy: 0.1225\n","Epoch 44/50\n","282/282 [==============================] - 36s 128ms/step - loss: 0.2461 - accuracy: 0.9623 - val_loss: 9.6320 - val_accuracy: 0.1226\n","Epoch 45/50\n","282/282 [==============================] - 37s 129ms/step - loss: 0.2269 - accuracy: 0.9659 - val_loss: 9.7257 - val_accuracy: 0.1218\n","Epoch 46/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.2090 - accuracy: 0.9690 - val_loss: 9.8084 - val_accuracy: 0.1229\n","Epoch 47/50\n","282/282 [==============================] - 36s 129ms/step - loss: 0.1956 - accuracy: 0.9712 - val_loss: 9.9085 - val_accuracy: 0.1227\n","Epoch 48/50\n","282/282 [==============================] - 37s 130ms/step - loss: 0.1918 - accuracy: 0.9720 - val_loss: 9.9732 - val_accuracy: 0.1247\n","Epoch 49/50\n","282/282 [==============================] - 38s 136ms/step - loss: 0.2842 - accuracy: 0.9449 - val_loss: 10.0307 - val_accuracy: 0.1201\n","Epoch 50/50\n","282/282 [==============================] - 38s 136ms/step - loss: 0.2701 - accuracy: 0.9484 - val_loss: 10.0850 - val_accuracy: 0.1212\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7bbbec2ad6f0>"]},"metadata":{},"execution_count":35}],"source":["batch_size = 64\n","epochs = 50\n","\n","# Prepare decoder input data that just contains the start token\n","decoder_input_train = np.hstack([np.zeros((target_train.shape[0], 1)), target_train[:, :-1]])\n","decoder_input_val = np.hstack([np.zeros((target_val.shape[0], 1)), target_val[:, :-1]])\n","\n","# Ensure targets are expanded in dimension to match the output shape expected by sparse_categorical_crossentropy\n","target_train_exp = np.expand_dims(target_train, -1)\n","target_val_exp = np.expand_dims(target_val, -1)\n","\n","# Checkpoint callback\n","# checkpoint_filepath = 'model_checkpoint_epoch_{epoch:02d}.h5'\n","checkpoint_filepath = '/content/drive/MyDrive/Colab Notebooks/models/model_checkpoint_epoch_{epoch:02d}.h5'\n","model_checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    save_freq='epoch'\n",")\n","\n","# Fit the model using the original integer labels\n","model.fit(\n","    [input_train, decoder_input_train], target_train_exp,\n","    validation_data=([input_val, decoder_input_val], target_val_exp),\n","    epochs=epochs, batch_size=batch_size, verbose=1,\n","    callbacks=[model_checkpoint_callback]\n",")"]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","# Load the model\n","model_path = '/content/drive/MyDrive/Colab Notebooks/models/model_checkpoint_epoch_50.h5'\n","custom_objects = {'Attention': Attention, 'AttentionLayer': AttentionLayer}\n","model = load_model(model_path, custom_objects=custom_objects)\n","\n","# Summary of the loaded model\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qOM8hUNBZh_I","executionInfo":{"status":"ok","timestamp":1715931108394,"user_tz":-180,"elapsed":9643,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}},"outputId":"0d40abc1-cd8b-40a9-c55b-c957b62160f6"},"id":"qOM8hUNBZh_I","execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_11 (InputLayer)       [(None, None)]               0         []                            \n","                                                                                                  \n"," embedding_4 (Embedding)     (None, None, 50)             2379000   ['input_11[0][0]']            \n","                                                                                                  \n"," input_12 (InputLayer)       [(None, None)]               0         []                            \n","                                                                                                  \n"," bidirectional_1 (Bidirecti  [(None, None, 512),          628736    ['embedding_4[0][0]']         \n"," onal)                        (None, 256),                                                        \n","                              (None, 256),                                                        \n","                              (None, 256),                                                        \n","                              (None, 256)]                                                        \n","                                                                                                  \n"," embedding_5 (Embedding)     (None, None, 50)             2379000   ['input_12[0][0]']            \n","                                                                                                  \n"," concatenate_5 (Concatenate  (None, 512)                  0         ['bidirectional_1[0][1]',     \n"," )                                                                   'bidirectional_1[0][3]']     \n","                                                                                                  \n"," concatenate_6 (Concatenate  (None, 512)                  0         ['bidirectional_1[0][2]',     \n"," )                                                                   'bidirectional_1[0][4]']     \n","                                                                                                  \n"," lstm_3 (LSTM)               [(None, None, 512),          1153024   ['embedding_5[0][0]',         \n","                              (None, 512),                           'concatenate_5[0][0]',       \n","                              (None, 512)]                           'concatenate_6[0][0]']       \n","                                                                                                  \n"," attention_layer_1 (Attenti  (None, None, 512)            10271     ['lstm_3[0][0]',              \n"," onLayer)                                                            'bidirectional_1[0][0]']     \n","                                                                                                  \n"," concatenate_7 (Concatenate  (None, None, 1024)           0         ['attention_layer_1[0][0]',   \n"," )                                                                   'lstm_3[0][0]']              \n","                                                                                                  \n"," dense_10 (Dense)            (None, None, 47580)          4876950   ['concatenate_7[0][0]']       \n","                                                          0                                       \n","                                                                                                  \n","==================================================================================================\n","Total params: 55319531 (211.03 MB)\n","Trainable params: 55319531 (211.03 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Encoder inference model\n","encoder_model = Model(encoder_inputs, [encoder_outputs, forward_h, forward_c, backward_h, backward_c])\n","\n","# Decoder inference model\n","decoder_state_input_h = Input(shape=(512,))\n","decoder_state_input_c = Input(shape=(512,))\n","encoder_outputs_input = Input(shape=(None, 512))\n","decoder_inputs_single = Input(shape=(1,))\n","\n","# Embedding layer\n","decoder_embedding_layer = Embedding(vocab_size, 50, mask_zero=True)\n","decoder_embedding_single = decoder_embedding_layer(decoder_inputs_single)\n","\n","# LSTM layer\n","decoder_lstm_outputs, state_h, state_c = decoder_lstm(\n","    decoder_embedding_single, initial_state=[decoder_state_input_h, decoder_state_input_c])\n","\n","# Context vector from attention mechanism\n","context_vector = attention_layer([decoder_lstm_outputs, encoder_outputs_input])\n","\n","# Concatenate context vector with LSTM outputs\n","decoder_concat_input = Concatenate(axis=-1)([context_vector, decoder_lstm_outputs])\n","\n","# Dense layer\n","decoder_outputs = decoder_dense(decoder_concat_input)\n","\n","# Decoder inference model\n","decoder_model = Model(\n","    [decoder_inputs_single, encoder_outputs_input, decoder_state_input_h, decoder_state_input_c],\n","    [decoder_outputs, state_h, state_c]\n",")\n"],"metadata":{"id":"aC3YHukzFmUv","executionInfo":{"status":"ok","timestamp":1715931109036,"user_tz":-180,"elapsed":653,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"id":"aC3YHukzFmUv","execution_count":89,"outputs":[]},{"cell_type":"markdown","id":"2d6f5083-762f-44b2-b288-d3db4b300b67","metadata":{"id":"2d6f5083-762f-44b2-b288-d3db4b300b67"},"source":["## Save the model"]},{"cell_type":"code","execution_count":90,"id":"df7b2e31-94ad-4c23-86bb-a45ea94b7ca9","metadata":{"id":"df7b2e31-94ad-4c23-86bb-a45ea94b7ca9","executionInfo":{"status":"ok","timestamp":1715931109037,"user_tz":-180,"elapsed":6,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[],"source":["# data_dir = os.path.join(os.getcwd(), 'data')\n","# file_path_h5 = os.path.join(data_dir, 's2s_model.h5')\n","# model.save(file_path_h5)"]},{"cell_type":"markdown","id":"dbd427b4-179f-426d-b55e-42f79a699b56","metadata":{"id":"dbd427b4-179f-426d-b55e-42f79a699b56"},"source":["## Generate responses"]},{"cell_type":"code","execution_count":94,"id":"9efe1ba9-1c2a-4ab4-9287-661e0361b40a","metadata":{"id":"9efe1ba9-1c2a-4ab4-9287-661e0361b40a","executionInfo":{"status":"ok","timestamp":1715931177022,"user_tz":-180,"elapsed":228,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"outputs":[],"source":["initial_preprocessing = False # Excepts spaCy to detect and remove names from the text\n","max_length = 15\n","\n","# Generate response function\n","def generate_response(input_text: str) -> str:\n","    text = preprocess_text(input_text)\n","    print(f\"Preprocessed text: {text}\")\n","    input_seq = tokenizer.texts_to_sequences([text])\n","    print(f\"Input sequence: {input_seq}\")\n","    input_seq = pad_sequences(input_seq, maxlen=max_length, padding='post', truncating='post')\n","    print(f\"Padded input sequence: {input_seq}\")\n","\n","    # Get the encoder states and encoder outputs\n","    encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_model.predict(input_seq)\n","    state_h = np.concatenate([forward_h, backward_h], axis=-1)\n","    state_c = np.concatenate([forward_c, backward_c], axis=-1)\n","    states_value = [state_h, state_c]\n","\n","    # Prepare the target sequence with the start token\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = tokenizer.word_index['start']\n","\n","    stop_condition = False\n","    decoded_sentence = ''\n","    tokens_generated = 0\n","\n","    while not stop_condition:\n","        decoder_outputs, h, c = decoder_model.predict([target_seq, encoder_outputs, state_h, state_c], verbose=0)\n","\n","        sampled_token_index = np.argmax(decoder_outputs[0, -1, :])\n","        sampled_token = tokenizer.index_word.get(sampled_token_index, '')\n","\n","        if sampled_token == 'end' or tokens_generated > max_length:\n","            stop_condition = True\n","        else:\n","            decoded_sentence += ' ' + sampled_token\n","            tokens_generated += 1\n","\n","            target_seq = np.zeros((1, 1))\n","            target_seq[0, 0] = sampled_token_index\n","            states_value = [h, c]\n","\n","    return decoded_sentence.strip()"]},{"cell_type":"markdown","id":"dea4106f-4db4-4de6-bb5a-9b5403c1aa57","metadata":{"id":"dea4106f-4db4-4de6-bb5a-9b5403c1aa57"},"source":["## Testing"]},{"cell_type":"code","execution_count":95,"id":"02d0ebd3-45bf-4088-8605-122834513d96","metadata":{"id":"02d0ebd3-45bf-4088-8605-122834513d96","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715931196941,"user_tz":-180,"elapsed":17084,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}},"outputId":"5e22c8c7-ecc3-4ef1-9309-85ebbb81a0ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","User:     Is she okay?\n","Preprocessed text: sofs is she okay ? eofs\n","Input sequence: [[1, 18, 51, 111, 2]]\n","Padded input sequence: [[  1  18  51 111   2   0   0   0   0   0   0   0   0   0   0]]\n","1/1 [==============================] - 0s 29ms/step\n","Bot:           fahzer lcd samoans catholicism inspire overflow effective retina overflow effective retina overflow effective retina overflow effective\n","-----------------------------\n","\n","User:     How are you feeling today?\n","Preprocessed text: sofs how are you feeling today ? eofs\n","Input sequence: [[1, 55, 34, 3, 549, 326, 2]]\n","Padded input sequence: [[  1  55  34   3 549 326   2   0   0   0   0   0   0   0   0]]\n","1/1 [==============================] - 0s 23ms/step\n","Bot:           conroy anouk eyefuck cynical sharply surround java sailors lookee apeshit cynical sharply surround java sailors lookee\n","-----------------------------\n","\n","User:     Hi there!\n","Preprocessed text: sofs hi there ! eofs\n","Input sequence: [[1, 357, 42, 2]]\n","Padded input sequence: [[  1 357  42   2   0   0   0   0   0   0   0   0   0   0   0]]\n","1/1 [==============================] - 0s 24ms/step\n","Bot:           rusesabagina sector'll effective rusesabagina sector'll effective rusesabagina sector'll effective rusesabagina sector'll effective rusesabagina sector'll effective rusesabagina\n","-----------------------------\n","\n","User:     Can you tell me the weather forecast for today?\n","Preprocessed text: sofs can you tell me the weather forecast for today ? eofs\n","Input sequence: [[1, 54, 3, 85, 17, 5, 1462, 22, 326, 2]]\n","Padded input sequence: [[   1   54    3   85   17    5 1462   22  326    2    0    0    0    0\n","     0]]\n","1/1 [==============================] - 0s 25ms/step\n","Bot:           cottages jesse surround tripp surround tripp surround tripp surround tripp surround tripp surround tripp surround tripp\n","-----------------------------\n","\n","User:     I think artificial intelligence is changing the world.\n","Preprocessed text: sofs i think artificial intelligence is changing the world . eofs\n","Input sequence: [[1, 4, 58, 7969, 1921, 18, 2385, 5, 243, 2]]\n","Padded input sequence: [[   1    4   58 7969 1921   18 2385    5  243    2    0    0    0    0\n","     0]]\n","1/1 [==============================] - 0s 23ms/step\n","Bot:           fahzer gollies succubus succubus succubus succubus succubus succubus succubus succubus succubus succubus succubus succubus succubus succubus\n","-----------------------------\n","\n","User:     Any good movie recommendations?\n","Preprocessed text: sofs any good movie recommendations ? eofs\n","Input sequence: [[1, 119, 74, 604, 9726, 2]]\n","Padded input sequence: [[   1  119   74  604 9726    2    0    0    0    0    0    0    0    0\n","     0]]\n","1/1 [==============================] - 0s 25ms/step\n","Bot:           cloud ants grinned pattica overdrive bicentennial nigeria decompose marharagi assume gramps digits tungsten dunbar regroup apothecary\n","-----------------------------\n","\n","User:     What do you mean by that?\n","Preprocessed text: sofs what do you mean by that ? eofs\n","Input sequence: [[1, 15, 11, 3, 106, 125, 12, 2]]\n","Padded input sequence: [[  1  15  11   3 106 125  12   2   0   0   0   0   0   0   0]]\n","1/1 [==============================] - 0s 22ms/step\n","Bot:           enough paper'll suffused dictator merger hastily jockeying ventured ascribing bathhouse wittgenstein delayed hastily jockeying ventured ascribing\n","-----------------------------\n","\n","User:     I'm feeling really sad today.\n","Preprocessed text: sofs i'm feeling really sad today . eofs\n","Input sequence: [[1, 1201, 549, 112, 1200, 326, 2]]\n","Padded input sequence: [[   1 1201  549  112 1200  326    2    0    0    0    0    0    0    0\n","     0]]\n","1/1 [==============================] - 0s 26ms/step\n","Bot:           harv fishbowl hierarchies insults drastic harv fishbowl hierarchies insults drastic harv fishbowl hierarchies insults drastic harv\n","-----------------------------\n","\n","User:     What are the implications of quantum computing on cybersecurity?\n","Preprocessed text: sofs what are the implications of quantum computing on cybersecurity ? eofs\n","Input sequence: [[1, 15, 34, 5, 8231, 14, 7010, 30, 2]]\n","Padded input sequence: [[   1   15   34    5 8231   14 7010   30    2    0    0    0    0    0\n","     0]]\n","1/1 [==============================] - 0s 23ms/step\n","Bot:           kyle muster trapper sherman technicality teenager levitation matters matters matters matters matters matters matters matters matters\n","-----------------------------\n","\n","User:     Why did the chicken cross the road?\n","Preprocessed text: sofs why did the chicken cross the road ? eofs\n","Input sequence: [[1, 68, 41, 5, 1272, 1129, 5, 729, 2]]\n","Padded input sequence: [[   1   68   41    5 1272 1129    5  729    2    0    0    0    0    0\n","     0]]\n","1/1 [==============================] - 0s 23ms/step\n","Bot:           barrington barrington barrington barrington barrington barrington barrington barrington barrington barrington barrington barrington barrington barrington barrington barrington\n","-----------------------------\n","\n","User:     Can you explain the plot of The Matrix?\n","Preprocessed text: sofs can you explain the plot of the matrix ? eofs\n","Input sequence: [[1, 54, 3, 670, 5, 4403, 14, 5, 4470, 2]]\n","Padded input sequence: [[   1   54    3  670    5 4403   14    5 4470    2    0    0    0    0\n","     0]]\n","1/1 [==============================] - 0s 28ms/step\n","Bot:           negligence hell'd hell'd hell'd hell'd hell'd hell'd hell'd hell'd hell'd hell'd hell'd hell'd hell'd hell'd hell'd\n"]}],"source":["# Testing\n","print(\"\\nUser:     Is she okay?\")\n","print(\"Bot:          \", generate_response('Is she okay?'))\n","print(\"-----------------------------\")\n","print(\"\\nUser:     How are you feeling today?\")\n","print(\"Bot:          \", generate_response('How are you feeling today?'))\n","print(\"-----------------------------\")\n","print(\"\\nUser:     Hi there!\")\n","print(\"Bot:          \", generate_response('Hi there!'))\n","print(\"-----------------------------\")\n","print(\"\\nUser:     Can you tell me the weather forecast for today?\")\n","print(\"Bot:          \", generate_response('Can you tell me the weather forecast for today?'))\n","print(\"-----------------------------\")\n","print(\"\\nUser:     I think artificial intelligence is changing the world.\")\n","print(\"Bot:          \", generate_response('I think artificial intelligence is changing the world.'))\n","print(\"-----------------------------\")\n","print(\"\\nUser:     Any good movie recommendations?\")\n","print(\"Bot:          \", generate_response('Any good movie recommendations?'))\n","print(\"-----------------------------\")\n","print(\"\\nUser:     What do you mean by that?\")\n","print(\"Bot:          \", generate_response('What do you mean by that?'))\n","print(\"-----------------------------\")\n","print(\"\\nUser:     I'm feeling really sad today.\")\n","print(\"Bot:          \", generate_response(\"I'm feeling really sad today.\"))\n","print(\"-----------------------------\")\n","print(\"\\nUser:     What are the implications of quantum computing on cybersecurity?\")\n","print(\"Bot:          \", generate_response('What are the implications of quantum computing on cybersecurity?'))\n","print(\"-----------------------------\")\n","print(\"\\nUser:     Why did the chicken cross the road?\")\n","print(\"Bot:          \", generate_response('Why did the chicken cross the road?'))\n","print(\"-----------------------------\")\n","print(\"\\nUser:     Can you explain the plot of The Matrix?\")\n","print(\"Bot:          \", generate_response('Can you explain the plot of The Matrix?'))"]},{"cell_type":"code","source":[],"metadata":{"id":"LFyTeFaZcEan","executionInfo":{"status":"ok","timestamp":1715931129686,"user_tz":-180,"elapsed":13,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"id":"LFyTeFaZcEan","execution_count":92,"outputs":[]},{"cell_type":"markdown","source":["## Save the model in Google Drive"],"metadata":{"id":"ufRnNzFWvMFK"},"id":"ufRnNzFWvMFK"},{"cell_type":"code","source":["# data_dir = '/content/drive/MyDrive/Colab Notebooks/models'\n","# if not os.path.exists(data_dir):\n","#     os.makedirs(data_dir)\n","\n","# file_path_h5 = os.path.join(data_dir, 's2s_model.h5')\n","# model.save(file_path_h5)\n"],"metadata":{"id":"UwnZ1yKLtAW7","executionInfo":{"status":"ok","timestamp":1715931129686,"user_tz":-180,"elapsed":12,"user":{"displayName":"Tomas Suslavicius","userId":"14151871739646404131"}}},"id":"UwnZ1yKLtAW7","execution_count":93,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":5}