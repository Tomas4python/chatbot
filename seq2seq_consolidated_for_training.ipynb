{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ZiOK0MWE7d",
   "metadata": {
    "id": "b0ZiOK0MWE7d"
   },
   "source": [
    "## GPU info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bhvFI7ztVLRy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhvFI7ztVLRy",
    "outputId": "f14b8dc5-e880-4726-d34b-ddc0ee413a3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 15 08:28:50 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   77C    P0              34W /  70W |   1191MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db509470-cb51-4c21-84ca-5f928073d68e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db509470-cb51-4c21-84ca-5f928073d68e",
    "outputId": "ffc7cdf0-1bfb-4ddd-cd8a-53456cb58ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Name: /device:GPU:0\n",
      "Memory Limit: 14626652160 bytes\n",
      "Description: device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_gpu_details():\n",
    "    devices = device_lib.list_local_devices()\n",
    "    for device in devices:\n",
    "        if device.device_type == 'GPU':\n",
    "            print(f\"Device Name: {device.name}\")\n",
    "            print(f\"Memory Limit: {device.memory_limit} bytes\")\n",
    "            print(f\"Description: {device.physical_device_desc}\")\n",
    "\n",
    "get_gpu_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648d492-f4e0-40a8-a3ff-012fa0a0d293",
   "metadata": {
    "id": "6648d492-f4e0-40a8-a3ff-012fa0a0d293"
   },
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0af574-6748-467b-8ba6-4da51794c5b9",
   "metadata": {
    "id": "8a0af574-6748-467b-8ba6-4da51794c5b9"
   },
   "outputs": [],
   "source": [
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e2a98-f1d4-4f72-b95e-6a75f457e8e8",
   "metadata": {
    "id": "7e4e2a98-f1d4-4f72-b95e-6a75f457e8e8"
   },
   "outputs": [],
   "source": [
    "# !pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29568f1-df35-42d2-85e3-cb2eee0cab2b",
   "metadata": {
    "id": "qmUZ9BB6NgmP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "# import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, Concatenate, Layer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y5srV6bjOpFb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5srV6bjOpFb",
    "outputId": "636deec5-1f24-44c9-a2f5-adc68745bbf9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')  # Tokenizer\n",
    "nltk.download('wordnet')  # Lemmatizer\n",
    "nltk.download('stopwords')  # Stopwords\n",
    "nltk.download('omw-1.4') # Ensures multilingual contexts\n",
    "\n",
    "# Stopwords list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "initial_preprocessing = True\n",
    "\n",
    "# # Load spaCy's English NLP model\n",
    "# nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5150d2f-999d-45ad-b2f2-b9b65b883e89",
   "metadata": {
    "id": "f5150d2f-999d-45ad-b2f2-b9b65b883e89"
   },
   "source": [
    "## Create prepocessing functions for initial text and later response generation preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8f237-5274-43ee-8ac2-964dd9214ae5",
   "metadata": {
    "id": "f0e8f237-5274-43ee-8ac2-964dd9214ae5"
   },
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    # Normalize Unicode string to NFKD form, remove non-ASCII characters, and then decode it back to a UTF-8 string\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Add a space before any punctuation mark (., !, or ?)\n",
    "    text = re.sub(r\"([.!?])\", r\" \\1\", text)\n",
    "    # Handle contractions correctly by not adding space before apostrophe\n",
    "    text = re.sub(r\"(\\b\\w+)'(d|s|t|ll|ve|re)\", r\"\\1'\\2\", text)\n",
    "    # Replace any sequence of characters that are not letters, keep basic punctuation\n",
    "    text = re.sub(r\"[^a-z.,'!? ]\", ' ', text)\n",
    "    # Replace any sequence of whitespace characters with a single space and remove leading and trailing whitespace\n",
    "    text = re.sub(r\"\\s+\", r\" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def remove_names(text: str) -> str:\n",
    "    # Use spaCy to detect and remove names from the text\n",
    "    doc = nlp(text)\n",
    "    filtered_text = ' '.join([token.text for token in doc if token.ent_type_ != 'PERSON']) # Takes really long time, exlude from chatbot input preprocessing\n",
    "    return filtered_text\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    # Normalize text\n",
    "    text = normalize_text(text)\n",
    "    # Remove names using spaCy's NER\n",
    "    if initial_preprocessing:\n",
    "        text = remove_names(text)\n",
    "    # # Remove punctuation\n",
    "    # text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stopwords and tokenize\n",
    "    # words = word_tokenize(text) # More intelligent splitting\n",
    "    # filtered_words = [word for word in words if word not in stop_words]\n",
    "    # # Lemmatize words\n",
    "    # lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    # Add <SOS> and <EOS> tokens, and join the list into a single string\n",
    "    # return ' '.join(['sofs'] + lemmatized_words + ['eofs'])\n",
    "    return 'sofs ' + text + ' eofs' # Chosen ['sofs', 'eofs'] because tokenizer removes everthing what is in <> or || and are not in dataset vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e332df38-04f5-4261-a544-786538749051",
   "metadata": {
    "id": "e332df38-04f5-4261-a544-786538749051"
   },
   "source": [
    "## Load the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e087632-daab-4026-862e-0c7b33ebe0fa",
   "metadata": {
    "id": "3e087632-daab-4026-862e-0c7b33ebe0fa"
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer from file\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "tokenizer_path = os.path.join(data_dir, 'tokenizer.pickle')\n",
    "with open(tokenizer_path, 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78c771-eb63-499b-9f47-483d825bf9db",
   "metadata": {
    "id": "4c78c771-eb63-499b-9f47-483d825bf9db",
    "outputId": "8770a659-78f4-44ab-8241-6c89d1905eeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['sofs'], tokenizer.word_index['eofs']) # Checking if <start> and <end> tokens are in index (vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed2bb9f-a5db-4bf1-962d-810dabe5247c",
   "metadata": {
    "id": "eed2bb9f-a5db-4bf1-962d-810dabe5247c",
    "outputId": "95aa74d2-c680-4db8-b6b3-938e0e7af512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sofs', 304713), ('eofs', 304713), ('know', 22895), ('like', 15314), ('get', 15014), ('got', 13322), ('u', 13080), ('want', 12128), ('think', 11251), ('one', 11186)]\n",
      "[('ese', 1), ('whatchu', 1), ('mafiya', 1), ('chechnya', 1), ('toady', 1), ('betterment', 1), ('ivans', 1), ('nihilistic', 1), ('freelancing', 1), ('gatherer', 1), ('overview', 1), ('retardant', 1), ('deploys', 1), ('beastie', 1), ('ozzfest', 1), ('russkie', 1), ('shaver', 1), ('polynesia', 1), ('mersh', 1), ('slovo', 1), ('dawning', 1), ('tshirt', 1), ('dishonorably', 1), ('vandal', 1), ('grozny', 1), ('lamborghini', 1), ('genoa', 1), ('pizda', 1), ('filament', 1), ('replicate', 1), ('solider', 1), ('secaucus', 1), ('athletics', 1), ('herded', 1), ('wolverine', 1), ('absorbs', 1), ('definitively', 1), ('poppycock', 1), ('rumous', 1), ('celery', 1), ('cerebrum', 1), ('unashamedly', 1), ('dien', 1), ('gerhart', 1), ('mending', 1), ('galvanism', 1), ('equalize', 1), ('cerebrospinal', 1), ('madein', 1), ('froderick', 1), ('blindingly', 1), ('ascend', 1), ('diagnostician', 1), ('sockers', 1), ('fockers', 1), ('fredereck', 1), ('frodereck', 1), ('fronkon', 1), ('ereck', 1), ('dereck', 1), ('mmmmmmmmmm', 1), ('mmmmmmmmmmmmmmmmmmmmmmmmm', 1), ('pah', 1), ('mmmmmmmmmmm', 1), ('mmmmmmmmmmmmmnnnnnnmmmmmmmm', 1), ('transylvanian', 1), ('apfelstrudel', 1), ('mmmmmmmmmmmmmmm', 1), ('fuchsmachen', 1), ('liebe', 1), ('danc', 1), ('ul', 1), ('tra', 1), ('sacral', 1), ('minuteness', 1), ('schwanzstucker', 1), ('grrrhmmnnnjkjmmmnn', 1), ('roughhousing', 1), ('foooooood', 1), ('dooty', 1), ('lifebuoy', 1), ('saij', 1), ('peifecl', 1), ('meseif', 1), ('wellington', 1), ('lorj', 1), ('cetshwayo', 1), ('manoeuvre', 1), ('indeedldid', 1), ('mylord', 1), ('itwas', 1), ('ofthe', 1), ('adc', 1), ('ofnatal', 1), ('subaltern', 1), ('horsemanship', 1), ('splendil', 1), ('bombardier', 1), ('impi', 1), ('basuto', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Top words in dictionary\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Sort the word_counts dictionary by frequency in descending order\n",
    "sorted_word_counts = OrderedDict(sorted(tokenizer.word_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Display the sorted word counts\n",
    "print(list(sorted_word_counts.items())[:10])\n",
    "print(list(sorted_word_counts.items())[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01444ef2-087e-4f5e-9a6a-26c9c63c9b8d",
   "metadata": {
    "id": "01444ef2-087e-4f5e-9a6a-26c9c63c9b8d"
   },
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3699bc1-d5ec-41d6-ba0f-de02b3905615",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "e3699bc1-d5ec-41d6-ba0f-de02b3905615",
    "outputId": "4149a199-702e-47d7-83d6-d7811673d71e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "training_data_final"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-11ddca9b-1256-425c-bd43-1dcaf127d57f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Input</th>\n",
       "      <th>Padded_Input_Sequences</th>\n",
       "      <th>ID_Response</th>\n",
       "      <th>Padded_Target_Sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1044</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L1045</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L984</td>\n",
       "      <td>[1, 38, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L985</td>\n",
       "      <td>[1, 235, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L924</td>\n",
       "      <td>[1, 791, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L925</td>\n",
       "      <td>[1, 28, 11, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L871</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L872</td>\n",
       "      <td>[1, 38, 45, 36, 42, 514, 421, 2, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L870</td>\n",
       "      <td>[1, 541, 3, 349, 590, 3, 663, 2, 0, 0]</td>\n",
       "      <td>L871</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L868</td>\n",
       "      <td>[1, 131, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L869</td>\n",
       "      <td>[1, 4, 725, 813, 2, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L867</td>\n",
       "      <td>[1, 19, 205, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L868</td>\n",
       "      <td>[1, 131, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L866</td>\n",
       "      <td>[1, 664, 5, 19, 205, 1913, 2, 0, 0, 0]</td>\n",
       "      <td>L867</td>\n",
       "      <td>[1, 19, 205, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L864</td>\n",
       "      <td>[1, 6220, 2142, 4, 1551, 2, 0, 0, 0, 0]</td>\n",
       "      <td>L865</td>\n",
       "      <td>[1, 117, 97, 132, 10, 213, 2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L863</td>\n",
       "      <td>[1, 913, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>L864</td>\n",
       "      <td>[1, 6220, 2142, 4, 1551, 2, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11ddca9b-1256-425c-bd43-1dcaf127d57f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-11ddca9b-1256-425c-bd43-1dcaf127d57f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-11ddca9b-1256-425c-bd43-1dcaf127d57f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-c369129f-81af-4526-b4a1-93adc165fad1\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c369129f-81af-4526-b4a1-93adc165fad1')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-c369129f-81af-4526-b4a1-93adc165fad1 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  ID_Input                   Padded_Input_Sequences ID_Response  \\\n",
       "0    L1044           [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]       L1045   \n",
       "1     L984          [1, 38, 2, 0, 0, 0, 0, 0, 0, 0]        L985   \n",
       "2     L924         [1, 791, 2, 0, 0, 0, 0, 0, 0, 0]        L925   \n",
       "3     L871           [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]        L872   \n",
       "4     L870   [1, 541, 3, 349, 590, 3, 663, 2, 0, 0]        L871   \n",
       "5     L868         [1, 131, 2, 0, 0, 0, 0, 0, 0, 0]        L869   \n",
       "6     L867        [1, 19, 205, 2, 0, 0, 0, 0, 0, 0]        L868   \n",
       "7     L866   [1, 664, 5, 19, 205, 1913, 2, 0, 0, 0]        L867   \n",
       "8     L864  [1, 6220, 2142, 4, 1551, 2, 0, 0, 0, 0]        L865   \n",
       "9     L863         [1, 913, 2, 0, 0, 0, 0, 0, 0, 0]        L864   \n",
       "\n",
       "                   Padded_Target_Sequences  \n",
       "0           [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1         [1, 235, 2, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2         [1, 28, 11, 2, 0, 0, 0, 0, 0, 0]  \n",
       "3   [1, 38, 45, 36, 42, 514, 421, 2, 0, 0]  \n",
       "4           [1, 2, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "5       [1, 4, 725, 813, 2, 0, 0, 0, 0, 0]  \n",
       "6         [1, 131, 2, 0, 0, 0, 0, 0, 0, 0]  \n",
       "7        [1, 19, 205, 2, 0, 0, 0, 0, 0, 0]  \n",
       "8   [1, 117, 97, 132, 10, 213, 2, 0, 0, 0]  \n",
       "9  [1, 6220, 2142, 4, 1551, 2, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the DataFrame\n",
    "file_path_parquet = os.path.join(data_dir, 'training_df_s2s.parquet')\n",
    "training_data_final = pd.read_parquet(file_path_parquet)\n",
    "\n",
    "training_data_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd540b8-2163-45ed-ba7b-c888e8eccb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52e65d15-20cc-45ed-a490-f9e04ec7330a",
   "metadata": {},
   "source": [
    "# Encoder-decoder architecture with Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7bb8ea-317a-473d-b081-fb3c6e425128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, Concatenate, Layer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc79e52-4f84-48ba-9313-dc2188467df0",
   "metadata": {},
   "source": [
    "## Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7cdf18-2ada-433a-a343-b06501abec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)\n",
    "        self.V = Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(query_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = Attention(units)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        decoder_outputs, encoder_outputs = inputs\n",
    "        context_vectors, _ = tf.map_fn(lambda x: self.attention(x[0], x[1]),\n",
    "                                       (decoder_outputs, tf.tile(tf.expand_dims(encoder_outputs, axis=1),\n",
    "                                                                 [1, tf.shape(decoder_outputs)[1], 1, 1])),\n",
    "                                       fn_output_signature=(tf.TensorSpec(shape=(None, encoder_outputs.shape[-1]), dtype=tf.float32),\n",
    "                                                            tf.TensorSpec(shape=(None, None, 1), dtype=tf.float32)))\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c2771-8673-477e-9c69-36fe31161d4b",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a19eb1-be04-4468-8d62-29bffe7c1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = np.array(training_data_final['Padded_Input_Sequences'].tolist())\n",
    "target_sequences = np.array(training_data_final['Padded_Target_Sequences'].tolist())\n",
    "\n",
    "# Splitting the data into training and validation sets\n",
    "input_train, input_val, target_train, target_val = train_test_split(input_sequences, target_sequences, test_size=0.1, random_state=22)\n",
    "\n",
    "# Building the model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(vocab_size, 50, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(\n",
    "    LSTM(256, return_state=True, return_sequences=True))(encoder_embedding)\n",
    "encoder_states = [Concatenate()([forward_h, backward_h]), Concatenate()([forward_c, backward_c])]\n",
    "encoder_outputs = encoder_lstm\n",
    "\n",
    "# Attention Mechanism\n",
    "attention_units = 10\n",
    "attention_layer = AttentionLayer(attention_units)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(vocab_size, 50, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(512, return_sequences=True, return_state=True)\n",
    "decoder_lstm_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "# Apply attention to each time step in the decoder\n",
    "context_vectors = attention_layer([decoder_lstm_outputs, encoder_outputs])\n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1)([context_vectors, decoder_lstm_outputs])\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Main Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca75d8-20d4-4508-8510-41998137ade6",
   "metadata": {
    "id": "8837a228-860d-4392-a1b7-e243ef860509"
   },
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86055360-706e-4f44-9181-311b9029488f",
   "metadata": {
    "id": "7dee43c3-fdce-46ca-934d-7610c7da1bed"
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "file_path_h5 = os.path.join(data_dir, 's2s_model.h5')\n",
    "\n",
    "# Load the model\n",
    "model = load_model(file_path_h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504957c2-6f60-45b0-b1f0-5729778d1159",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4990b26-62da-4563-af60-d4ee2faa8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 3\n",
    "\n",
    "# Prepare decoder input data that just contains the start token\n",
    "decoder_input_train = np.hstack([np.zeros((target_train.shape[0], 1)), target_train[:, :-1]])\n",
    "decoder_input_val = np.hstack([np.zeros((target_val.shape[0], 1)), target_val[:, :-1]])\n",
    "\n",
    "# Ensure targets are expanded in dimension to match the output shape expected by sparse_categorical_crossentropy\n",
    "target_train_exp = np.expand_dims(target_train, -1)\n",
    "target_val_exp = np.expand_dims(target_val, -1)\n",
    "\n",
    "# Checkpoint callback\n",
    "checkpoint_filepath = 'model_checkpoint_epoch_{epoch:02d}.h5'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch',\n",
    "    period=5\n",
    ")\n",
    "\n",
    "# Fit the model using the original integer labels\n",
    "model.fit(\n",
    "    [input_train, decoder_input_train], target_train_exp,\n",
    "    validation_data=([input_val, decoder_input_val], target_val_exp),\n",
    "    epochs=epochs, batch_size=batch_size, verbose=1,\n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6f5083-762f-44b2-b288-d3db4b300b67",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b2e31-94ad-4c23-86bb-a45ea94b7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "file_path_h5 = os.path.join(data_dir, 's2s_model.h5')\n",
    "model.save(file_path_h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd427b4-179f-426d-b55e-42f79a699b56",
   "metadata": {},
   "source": [
    "## Generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe1ba9-1c2a-4ab4-9287-661e0361b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_preprocessing = False # Excepts spaCy to detect and remove names from the text\n",
    "\n",
    "def generate_response(input_text: str) -> str:\n",
    "    processed_text = preprocess_text(input_text)\n",
    "    input_seq = tokenizer.texts_to_sequences([processed_text])\n",
    "    input_seq = pad_sequences(input_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Get the encoder states and encoder outputs\n",
    "    encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_model.predict(input_seq)\n",
    "    state_h = np.concatenate([forward_h, backward_h], axis=-1)\n",
    "    state_c = np.concatenate([forward_c, backward_c], axis=-1)\n",
    "    states_value = [state_h, state_c]\n",
    "\n",
    "    # Prepare the target sequence with the start token\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tokenizer.word_index['sofs']  # Start token index\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    tokens_generated = 0\n",
    "\n",
    "    while not stop_condition:\n",
    "        decoder_output, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        context_vector, _ = attention_layer(decoder_output, encoder_outputs)\n",
    "        decoder_output_with_context = np.concatenate([context_vector, decoder_output], axis=-1)\n",
    "        \n",
    "        sampled_token_index = np.argmax(decoder_output_with_context[0, -1, :])\n",
    "        sampled_char = tokenizer.index_word.get(sampled_token_index, '')\n",
    "\n",
    "        if sampled_token_index == tokenizer.word_index['eofs'] or tokens_generated > 10:  # Stop condition\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_char\n",
    "            tokens_generated += 1\n",
    "\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "            states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4106f-4db4-4de6-bb5a-9b5403c1aa57",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0ebd3-45bf-4088-8605-122834513d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "print(\"\\nUser:     Is she okay?\")\n",
    "print(\"Bot:          \", generate_response('she okay?'))\n",
    "print(\"-----------------------------\")\n",
    "print(\"\\nUser:     How are you feeling today?\")\n",
    "print(\"Bot:          \", generate_response('How are you feeling today?'))\n",
    "print(\"-----------------------------\")\n",
    "print(\"\\nUser:     Hi there!\")\n",
    "print(\"Bot:          \", generate_response('Hi there!'))\n",
    "print(\"-----------------------------\")\n",
    "print(\"\\nUser:     Can you tell me the weather forecast for today?\")\n",
    "print(\"Bot:          \", generate_response('Can you tell me the weather forecast for today?'))\n",
    "print(\"-----------------------------\")\n",
    "print(\"\\nUser:     I think artificial intelligence is changing the world.\")\n",
    "print(\"Bot:          \", generate_response('I think artificial intelligence is changing the world.'))\n",
    "print(\"-----------------------------\")\n",
    "print(\"\\nUser:     Any good movie recommendations?\")\n",
    "print(\"Bot:          \", generate_response('Any good movie recommendations?'))\n",
    "print(\"-----------------------------\")\n",
    "print(\"\\nUser:     What do you mean by that?\")\n",
    "print(\"Bot:          \", generate_response('What do you mean by that?'))\n",
    "print(\"-----------------------------\")\n",
    "print(\"\\nUser:     I'm feeling really sad today.\")\n",
    "print(\"Bot:          \", generate_response(\"I'm feeling really sad today.\"))\n",
    "print(\"-----------------------------\")\n",
    "print(\"\\nUser:     What are the implications of quantum computing on cybersecurity?\")\n",
    "print(\"Bot:          \", generate_response('What are the implications of quantum computing on cybersecurity?'))\n",
    "print(\"-----------------------------\")\n",
    "print(\"\\nUser:     Why did the chicken cross the road?\")\n",
    "print(\"Bot:          \", generate_response('Why did the chicken cross the road?'))\n",
    "print(\"-----------------------------\")\n",
    "print(\"\\nUser:     Can you explain the plot of The Matrix?\")\n",
    "print(\"Bot:          \", generate_response('Can you explain the plot of The Matrix?'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
